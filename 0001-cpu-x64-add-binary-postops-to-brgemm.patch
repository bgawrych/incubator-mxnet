From dd51b73b2582f946f62964778762e465e4aea30e Mon Sep 17 00:00:00 2001
From: Piotr Chmiel <piotr.chmiel@intel.com>
Date: Wed, 17 Feb 2021 07:50:53 -0800
Subject: [PATCH] cpu: x64: add binary postops to brgemm

cpu: x64: brgemm: jit: mark methods as const where applicable

cpu: x64: brgemm: group execute post processing args using named struct

cpu: x64: brgemm: remove redundant dst_d data type
---
 src/cpu/x64/brgemm/brgemm.cpp                 |  52 ++-
 src/cpu/x64/brgemm/brgemm.hpp                 |  18 +-
 src/cpu/x64/brgemm/brgemm_types.hpp           |  34 +-
 src/cpu/x64/brgemm/jit_brgemm_kernel.cpp      | 314 ++++++++++++------
 src/cpu/x64/jit_brgemm_1x1_conv.cpp           |  20 +-
 src/cpu/x64/jit_brgemm_conv.cpp               |  33 +-
 src/cpu/x64/jit_brgemm_conv.hpp               |   4 +-
 src/cpu/x64/jit_brgemm_conv_utils.cpp         |  45 ++-
 src/cpu/x64/jit_brgemm_inner_product.cpp      |  55 ++-
 src/cpu/x64/jit_brgemm_inner_product.hpp      |   4 +-
 .../x64/jit_brgemm_inner_product_utils.cpp    |  38 +--
 src/cpu/x64/jit_brgemm_primitive_conf.hpp     |   2 +-
 src/cpu/x64/jit_primitive_conf.hpp            |   3 +-
 src/cpu/x64/matmul/brgemm_matmul.cpp          |  46 ++-
 14 files changed, 441 insertions(+), 227 deletions(-)

diff --git a/src/cpu/x64/brgemm/brgemm.cpp b/src/cpu/x64/brgemm/brgemm.cpp
index 9f0c5eb1f..e1afc44d3 100644
--- a/src/cpu/x64/brgemm/brgemm.cpp
+++ b/src/cpu/x64/brgemm/brgemm.cpp
@@ -23,7 +23,7 @@
 
 #include "cpu/x64/brgemm/brgemm_types.hpp"
 #include "cpu/x64/cpu_barrier.hpp"
-
+#include "cpu/x64/injectors/jit_uni_postops_injector.hpp"
 namespace dnnl {
 namespace impl {
 namespace cpu {
@@ -70,7 +70,7 @@ void brgemm_kernel_execute(const brgemm_kernel_t *brg_kernel, int bs,
 
 void brgemm_kernel_execute_postops(const brgemm_kernel_t *brg_kernel, int bs,
         const brgemm_batch_element_t *batch, void *ptr_C, void *ptr_D,
-        const void *bias, const float *scales, void *scratch) {
+        const brgemm_post_ops_data_t &post_ops_data, void *scratch) {
     brgemm_kernel_params_t brgemm_p;
 
     brgemm_p.batch = batch;
@@ -79,17 +79,19 @@ void brgemm_kernel_execute_postops(const brgemm_kernel_t *brg_kernel, int bs,
     brgemm_p.ptr_C = ptr_C;
     brgemm_p.ptr_D = ptr_D;
     brgemm_p.ptr_buf = scratch;
-    brgemm_p.ptr_bias = bias;
-    brgemm_p.ptr_scales = scales;
+    brgemm_p.ptr_bias = post_ops_data.bias;
+    brgemm_p.ptr_scales = post_ops_data.scales;
     brgemm_p.do_post_ops = 1;
     brgemm_p.BS = bs;
+    brgemm_p.post_ops_binary_rhs_arg_vec = post_ops_data.binary_post_ops_rhs;
+    brgemm_p.oc_logical_off = post_ops_data.oc_logical_off;
     (*brg_kernel)(&brgemm_p);
 }
 
 void brgemm_kernel_execute_postops(const brgemm_kernel_t *brg_kernel, int bs,
         const void *addr_A, const void *addr_B,
         const brgemm_batch_element_t *batch, void *ptr_C, void *ptr_D,
-        const void *bias, const float *scales, void *scratch) {
+        const brgemm_post_ops_data_t &post_ops_data, void *scratch) {
     brgemm_kernel_params_t brgemm_p;
 
     brgemm_p.batch = batch;
@@ -98,10 +100,13 @@ void brgemm_kernel_execute_postops(const brgemm_kernel_t *brg_kernel, int bs,
     brgemm_p.ptr_C = ptr_C;
     brgemm_p.ptr_D = ptr_D;
     brgemm_p.ptr_buf = scratch;
-    brgemm_p.ptr_bias = bias;
-    brgemm_p.ptr_scales = scales;
+    brgemm_p.ptr_bias = post_ops_data.bias;
+    brgemm_p.ptr_scales = post_ops_data.scales;
     brgemm_p.do_post_ops = 1;
     brgemm_p.BS = bs;
+    brgemm_p.post_ops_binary_rhs_arg_vec = post_ops_data.binary_post_ops_rhs;
+    brgemm_p.oc_logical_off = post_ops_data.oc_logical_off;
+
     (*brg_kernel)(&brgemm_p);
 }
 
@@ -319,11 +324,12 @@ status_t brgemm_desc_init(brgemm_t *brg, cpu_isa_t isa,
     return status::success;
 }
 
-status_t brgemm_desc_set_postops(brgemm_t *brg, const primitive_attr_t *attr,
-        impl::data_type_t dt_d, int LDD, impl::data_type_t dt_bias) {
-    if (brg == nullptr) return status::invalid_arguments;
+status_t brgemm_desc_set_postops(brgemm_t *brg, const memory_desc_t *dst_md,
+        const primitive_attr_t *attr, int LDD, impl::data_type_t dt_bias) {
+    if (!brg || !dst_md) return status::invalid_arguments;
 
     brg->attr = attr;
+    brg->dst_md = dst_md;
 
     brg->with_bias = (dt_bias == data_type::undef) ? false : true;
     brg->dt_bias = dt_bias;
@@ -332,6 +338,7 @@ status_t brgemm_desc_set_postops(brgemm_t *brg, const primitive_attr_t *attr,
             : types::data_type_size(brg->dt_bias);
 
     brg->LDD = LDD;
+    const auto &dt_d = dst_md->data_type;
 
     if ((brg->dt_a == data_type::u8 && brg->dt_b == data_type::s8)
             && (!one_of(dt_d, data_type::u8, data_type::s8, data_type::s32,
@@ -349,17 +356,32 @@ status_t brgemm_desc_set_postops(brgemm_t *brg, const primitive_attr_t *attr,
             && (!one_of(dt_bias, data_type::undef, data_type::f32)))
         return status::unimplemented;
 
+    using namespace injector;
+
+    const auto &post_ops = brg->attr->post_ops_;
+
+    const int binary_ind = post_ops.find(primitive_kind::binary);
+    brg->with_binary = binary_ind != -1;
+    const memory_desc_wrapper dst_d(dst_md);
+
+    if ((brg->with_binary && !dst_md)
+            || !injector::post_ops_ok(
+                    post_ops_ok_args_t(avx512_common, {sum, eltwise, binary},
+                            post_ops, &dst_d, true /*sum_at_pos_0_only*/,
+                            false /*sum_requires_scale_one*/,
+                            {broadcasting_strategy_t::per_oc,
+                                    broadcasting_strategy_t::scalar})))
+        return status::unimplemented;
+
     brg->dt_d = dt_d;
     brg->typesize_D = types::data_type_size(brg->dt_d);
 
-    const auto &p = brg->attr->post_ops_;
-    const int sum_idx = p.find(primitive_kind::sum);
+    const int sum_idx = post_ops.find(primitive_kind::sum);
     brg->with_sum = sum_idx != -1;
-    brg->sum_scale = (sum_idx != -1) ? p.entry_[sum_idx].sum.scale : 0;
+    brg->sum_scale = (sum_idx != -1) ? post_ops.entry_[sum_idx].sum.scale : 0;
 
-    const int eltwise_ind = p.find(primitive_kind::eltwise);
+    const int eltwise_ind = post_ops.find(primitive_kind::eltwise);
     brg->with_eltwise = eltwise_ind != -1;
-    if (brg->with_eltwise) brg->eltwise = p.entry_[eltwise_ind].eltwise;
 
     if (brg->is_int8) {
         const auto &oscales = brg->attr->output_scales_;
diff --git a/src/cpu/x64/brgemm/brgemm.hpp b/src/cpu/x64/brgemm/brgemm.hpp
index b75dc1eb1..ff2585456 100644
--- a/src/cpu/x64/brgemm/brgemm.hpp
+++ b/src/cpu/x64/brgemm/brgemm.hpp
@@ -73,17 +73,17 @@ status_t brgemm_desc_init(brgemm_t *brg, cpu_isa_t isa,
 /// Adds post-operations to BRGEMM descriptor
 ///
 /// @param brg Output BRGEMM descriptor
+/// @param dst_md Specifies memory descriptor output tensor, need for binary
+// postops to determine
 /// @param attr Primitive attributes (can be NULL). Specifies element-wise
 ///     operations
-/// @param dt_d Specifies the data type of D matrix
-///     Can be u8, s8, s32, bf16 or fp32
 /// @param LDD Specifies the leading dimension of matrix D
 ///        LDD must be at least max(1, N)
 /// @param dt_bias Specifies the data type Bias
 ///     Can be u8, s8, s32, bf16 or fp32
 ///
-status_t brgemm_desc_set_postops(brgemm_t *brg, const primitive_attr_t *attr,
-        impl::data_type_t dt_d, int LDD,
+status_t brgemm_desc_set_postops(brgemm_t *brg, const memory_desc_t *dst_md,
+        const primitive_attr_t *attr, int LDD,
         impl::data_type_t dt_bias = impl::data_type::undef);
 
 /// Adds BRGEMM attributes to BRGEMM descriptor
@@ -155,14 +155,13 @@ void brgemm_kernel_execute(const brgemm_kernel_t *brg_kernel, int bs,
 ///     and virtual padding for matrices A
 /// @param ptr_C Pointer to matrix C
 /// @param ptr_D Pointer to destination matrix D
-/// @param bias Vector of bias (vector length is N)
-/// @param scales Vector of scales (vector length is N)
+/// @param post_ops_data Specifies tensors and data used in post processing phase
 /// @param scratch Scratchpad needed for AMX version, can be nullptr for
 ///     avx512 version
 ///
 void brgemm_kernel_execute_postops(const brgemm_kernel_t *brg_kernel, int bs,
         const brgemm_batch_element_t *batch, void *ptr_C, void *ptr_D,
-        const void *bias, const float *scales, void *scratch = nullptr);
+        const brgemm_post_ops_data_t &post_ops_data, void *scratch = nullptr);
 
 /// Execute BRGEMM kernel (brgemm_offs and brgemm_strd version)
 ///
@@ -176,15 +175,14 @@ void brgemm_kernel_execute_postops(const brgemm_kernel_t *brg_kernel, int bs,
 ///     and virtual padding for matrices A
 /// @param ptr_C Pointer to destination matrix C
 /// @param ptr_D Pointer to destination matrix D
-/// @param bias Vector of bias (vector length is N)
-/// @param scales Vector of scales (vector length is N)
+/// @param post_ops_data Specifies tensors and data used in post processing phase
 /// @param scratch Scratchpad needed for AMX version, can be nullptr for
 ///     avx512 version
 ///
 void brgemm_kernel_execute_postops(const brgemm_kernel_t *brg_kernel, int bs,
         const void *addr_A, const void *addr_B,
         const brgemm_batch_element_t *batch, void *ptr_C, void *ptr_D,
-        const void *bias, const float *scales, void *scratch = nullptr);
+        const brgemm_post_ops_data_t &post_ops_data, void *scratch = nullptr);
 
 /// AMX utilities: Creates a palette based on BRGEMM descriptor
 ///
diff --git a/src/cpu/x64/brgemm/brgemm_types.hpp b/src/cpu/x64/brgemm/brgemm_types.hpp
index 05936b0c4..bb3717e05 100644
--- a/src/cpu/x64/brgemm/brgemm_types.hpp
+++ b/src/cpu/x64/brgemm/brgemm_types.hpp
@@ -151,12 +151,13 @@ struct brgemm_t {
     bool with_sum;
     float sum_scale;
     bool with_eltwise;
+    bool with_binary;
     bool with_scales;
     bool req_s8s8_compensation;
     int is_oc_scale;
 
     const primitive_attr_t *attr;
-    post_ops_t::entry_t::eltwise_t eltwise;
+    const memory_desc_t *dst_md;
 
     brgemm_attr_t brgattr;
     static constexpr int MAX_VPAD = 100;
@@ -176,6 +177,13 @@ struct brgemm_kernel_params_t {
 
     size_t do_post_ops;
     size_t BS;
+
+    /*
+     * ptr to table of void * elements that are pointers to post_op binary
+     * src1 tensors
+     */
+    const void *post_ops_binary_rhs_arg_vec;
+    size_t oc_logical_off;
 };
 
 struct jit_brgemm_kernel_base_t;
@@ -193,6 +201,30 @@ private:
     DNNL_DISALLOW_COPY_AND_ASSIGN(brgemm_kernel_t);
 };
 
+/// @param bias Vector of bias (vector length is N)
+/// @param scales Vector of scales (vector length is N)
+/// @param binary_post_ops_rhs Ptr to table of void * elements that are pointers
+///                            to post_op binary * src1 tensors
+/// @param oc_logical_off - used in binary postops in per_oc bcast strategy,
+//                      offset to start oc processed by given thread in elements
+/// @param scratch Scratchpad needed for AMX version, can be nullptr for
+///     avx512 version
+///
+struct brgemm_post_ops_data_t {
+    brgemm_post_ops_data_t() = default;
+    brgemm_post_ops_data_t(const void *bias, const float *scales,
+            const void *binary_post_ops_rhs, size_t oc_logical_off)
+        : bias(bias)
+        , scales(scales)
+        , binary_post_ops_rhs(binary_post_ops_rhs)
+        , oc_logical_off(oc_logical_off) {}
+
+    const void *bias = nullptr;
+    const float *scales = nullptr;
+    const void *binary_post_ops_rhs = nullptr;
+    size_t oc_logical_off = 0;
+};
+
 } // namespace x64
 } // namespace cpu
 } // namespace impl
diff --git a/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp b/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp
index a22ff6e0d..90b43b197 100644
--- a/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp
+++ b/src/cpu/x64/brgemm/jit_brgemm_kernel.cpp
@@ -13,6 +13,7 @@
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *******************************************************************************/
+#include <memory>
 
 #include "common/c_types_map.hpp"
 #include "common/nstl.hpp"
@@ -22,7 +23,7 @@
 #include "cpu/x64/brgemm/brgemm_amx.hpp"
 #include "cpu/x64/brgemm/brgemm_types.hpp"
 #include "cpu/x64/cpu_barrier.hpp"
-#include "cpu/x64/injectors/jit_uni_eltwise_injector.hpp"
+#include "cpu/x64/injectors/jit_uni_postops_injector.hpp"
 #include "cpu/x64/jit_generator.hpp"
 
 #define GET_OFF(field) offsetof(brgemm_kernel_params_t, field)
@@ -40,27 +41,41 @@ struct jit_brgemm_kernel_base_t : public jit_generator {
     jit_brgemm_kernel_base_t(const brgemm_t &abrg)
         : jit_generator(nullptr, MAX_CODE_SIZE, true, avx512_common)
         , brg(abrg)
-        , eltwise_injector_(nullptr)
-        , is_ldb_loop(false) {
-        if (brg.with_eltwise) {
-            const auto &p = brg.attr->post_ops_;
-            const int eltwise_ind = p.find(primitive_kind::eltwise);
-
-            post_ops_t::entry_t::eltwise_t eltwise;
-            eltwise = p.entry_[eltwise_ind].eltwise;
-            eltwise_injector_ = new jit_uni_eltwise_injector_f32<avx512_common>(
-                    this, eltwise, true, rax, Xbyak::Opmask(1));
+        , postops_injector_(nullptr)
+        , is_ldb_loop(false)
+        , with_binary_per_oc_bcast_(brg.with_binary
+                  && binary_injector::any_binary_postop_rhs_per_oc_broadcast(
+                          brg.attr->post_ops_,
+                          memory_desc_wrapper(brg.dst_md))) {
+
+        if (brg.with_eltwise || brg.with_binary || brg.with_sum) {
+
+            static constexpr bool preserve_gpr = true;
+            static constexpr bool preserve_vmm = true;
+            static constexpr bool use_exact_tail_scalar_bcast = false;
+
+            const binary_injector::rhs_arg_static_params_t rhs_sp {
+                    static_cast<size_t>(Xbyak::Zmm(1).getIdx()), this->rdx,
+                    this->r10, preserve_gpr, preserve_vmm,
+                    GET_OFF(post_ops_binary_rhs_arg_vec),
+                    memory_desc_wrapper(brg.dst_md),
+                    static_cast<size_t>(brg.ldb_tail), ld_tail_mask,
+                    use_exact_tail_scalar_bcast};
+            const binary_injector::static_params_t bsp {this->param1, rhs_sp};
+
+            postops_injector_ = utils::make_unique<
+                    injector::jit_uni_postops_injector_t<avx512_common>>(
+                    this, brg.attr->post_ops_, bsp);
         }
     }
 
-    ~jit_brgemm_kernel_base_t() override { delete eltwise_injector_; }
-
     DECLARE_CPU_JIT_AUX_FUNCTIONS(jit_brgemm_kernel_base_t)
 
     brgemm_t brg;
 
 private:
-    jit_uni_eltwise_injector_f32<avx512_common> *eltwise_injector_;
+    std::unique_ptr<injector::jit_uni_postops_injector_t<avx512_common>>
+            postops_injector_;
 
     using reg64_t = const Xbyak::Reg64;
 
@@ -103,6 +118,9 @@ private:
     const reg64_t reg_bias = reg_rdb_loop;
     const reg64_t reg_scales = reg_rdb_loop;
     const reg64_t reg_aux_bias = reg_rdb_loop;
+    const reg64_t reg_binary_postops_oc_l = reg_rdb_loop;
+    const reg64_t reg_aux_binary_postops_oc_l = reg_rdb_loop;
+
     const reg64_t reg_aux_scales = reg_aux_B;
     const reg64_t reg_do_post_ops = reg_rdb_loop;
     const reg64_t reg_tmp_gpr = reg_rdb_loop;
@@ -129,9 +147,13 @@ private:
     constexpr static int reg_buf_offs_ = 80;
     constexpr static int reg_comp_offs_ = reg_buf_offs_;
     constexpr static int reg_aux_comp_offs_ = 88;
-    constexpr static int stack_space_needed_ = 96;
+    constexpr static int abi_param1_offs_ = 96;
+    constexpr static int reg_binary_postops_oc_l_offs_ = 104;
+    constexpr static int reg_aux_binary_postops_oc_l_offs_ = 112;
+    constexpr static int stack_space_needed_ = 120;
 
     bool is_ldb_loop;
+    const bool with_binary_per_oc_bcast_;
 
     Xbyak::Opmask ld_full_mask = Xbyak::Opmask(2);
     Xbyak::Opmask ld_tail_mask = Xbyak::Opmask(3);
@@ -146,12 +168,12 @@ private:
             assert(idx > 0);
             return Xbyak::Zmm(idx);
         } else
-            return Xbyak::Zmm(0);
+            return this->zmm0;
     }
 
     Xbyak::Zmm load(int ld = 0) {
         if (n_bcast_1_load) {
-            return Xbyak::Zmm(0);
+            return this->zmm0;
         } else {
             int idx = 31 - (brg.ld_block2 * brg.bd_block) - ld;
             assert(idx > 0);
@@ -159,15 +181,15 @@ private:
         }
     }
 
-    Xbyak::Zmm zmm_tmp_1() { return Xbyak::Zmm(0); }
-    Xbyak::Zmm zmm_tmp_2() { return Xbyak::Zmm(1); }
-    Xbyak::Zmm zmm_tmp_3() { return Xbyak::Zmm(2); }
-    Xbyak::Zmm zmm_inp_shift() { return Xbyak::Zmm(1); }
+    const Xbyak::Zmm &zmm_tmp_1() const noexcept { return this->zmm0; }
+    const Xbyak::Zmm &zmm_tmp_2() const noexcept { return this->zmm1; }
+    const Xbyak::Zmm &zmm_tmp_3() const noexcept { return this->zmm2; }
+    const Xbyak::Zmm &zmm_inp_shift() const noexcept { return this->zmm1; }
 
     Xbyak::Zmm zmm_mask(const Xbyak::Zmm zmm_in, bool mask_flag, bool store,
-            Xbyak::Opmask ktail_mask);
+            Xbyak::Opmask ktail_mask) const;
     Xbyak::Ymm ymm_mask(const Xbyak::Ymm ymm_in, bool mask_flag, bool store,
-            Xbyak::Opmask ktail_mask);
+            Xbyak::Opmask ktail_mask) const;
 
     void cvt2ps(data_type_t type_in, const Xbyak::Zmm zmm_in,
             const Xbyak::Operand &op, bool mask_flag, bool store,
@@ -184,7 +206,7 @@ private:
     void store_accumulators_apply_post_ops(
             int bd_block, int ld_block, bool is_ld_tail);
     void apply_alpha_beta(int bd_block, int ld_block, bool is_ld_tail);
-
+    void apply_post_ops(int bd_block, int ld_block2, bool is_ld_tail);
     void restore_A_B_matrices();
     void set_A_B_matrices();
 
@@ -202,98 +224,112 @@ private:
 
     void generate() override;
 
-    int A_offset(int bd, int rd, bool is_amx = false);
-    int B_offset(int ld, int rd, bool is_amx = false);
-    int C_offset(int bd, int ld);
-    int D_offset(int bd, int ld);
+    int A_offset(int bd, int rd, bool is_amx = false) const noexcept;
+    int B_offset(int ld, int rd, bool is_amx = false) const noexcept;
+    int C_offset(int bd, int ld) const noexcept;
+    int D_offset(int bd, int ld) const noexcept;
+
+    int rdb_A_offset() const noexcept;
+    int rdb_B_offset() const noexcept;
 
-    int rdb_A_offset();
-    int rdb_B_offset();
+    int ldb_B_offset(int ld_block2, bool is_tail = false) const noexcept;
+    int ldb_C_offset(int ld_block2, bool is_tail = false) const noexcept;
+    int ldb_D_offset(int ld_block2, bool is_tail = false) const noexcept;
 
-    int ldb_B_offset(int ld_block2, bool is_tail = false);
-    int ldb_C_offset(int ld_block2, bool is_tail = false);
-    int ldb_D_offset(int ld_block2, bool is_tail = false);
+    int bdb_A_offset(int bd_block2) const noexcept;
+    int bdb_C_offset(int bd_block2) const noexcept;
+    int bdb_D_offset(int bd_block2) const noexcept;
 
-    int bdb_A_offset(int bd_block2);
-    int bdb_C_offset(int bd_block2);
-    int bdb_D_offset(int bd_block2);
+    int bias_offset(int ld, bool is_tail = false) const noexcept;
+    int oc_logical_offset(int ld, bool is_tail = false) const noexcept;
 
-    int bias_offset(int ld, bool is_tail = false);
-    int compensations_offset(int ld, bool is_tail = false);
-    int scales_offset(int ld, bool is_tail = false);
+    int compensations_offset(int ld, bool is_tail = false) const noexcept;
+    int scales_offset(int ld, bool is_tail = false) const noexcept;
 
     bool n_bcast_1_load = false;
     bool vpad_exist = false;
 };
 
-int jit_brgemm_kernel_base_t::A_offset(int bd, int rd, bool is_amx) {
+int jit_brgemm_kernel_base_t::A_offset(int bd, int rd, bool is_amx) const
+        noexcept {
     return (is_amx) ? brg.typesize_A * (bd * brg.bd_block * brg.LDA)
                     : brg.typesize_A * (bd * brg.LDA + rd);
 }
-int jit_brgemm_kernel_base_t::B_offset(int ld, int rd, bool is_amx) {
+int jit_brgemm_kernel_base_t::B_offset(int ld, int rd, bool is_amx) const
+        noexcept {
     return (is_amx)
             ? brg.typesize_B * (brg.rd_step * ld * brg.ld_block)
             : brg.typesize_B * (rd * brg.LDB + brg.rd_step * ld * brg.ld_block);
 }
-int jit_brgemm_kernel_base_t::C_offset(int bd, int ld) {
+int jit_brgemm_kernel_base_t::C_offset(int bd, int ld) const noexcept {
     return brg.typesize_C * (bd * brg.LDC + ld * brg.ld_block);
 }
-int jit_brgemm_kernel_base_t::D_offset(int bd, int ld) {
+int jit_brgemm_kernel_base_t::D_offset(int bd, int ld) const noexcept {
     return brg.typesize_D * (bd * brg.LDD + ld * brg.ld_block);
 }
 
-int jit_brgemm_kernel_base_t::rdb_A_offset() {
+int jit_brgemm_kernel_base_t::rdb_A_offset() const noexcept {
     return brg.typesize_A * brg.rd_block;
 }
-int jit_brgemm_kernel_base_t::rdb_B_offset() {
+int jit_brgemm_kernel_base_t::rdb_B_offset() const noexcept {
     return brg.typesize_B * brg.rd_block * brg.LDB;
 }
 
-int jit_brgemm_kernel_base_t::ldb_B_offset(int ld_block2, bool is_tail) {
+int jit_brgemm_kernel_base_t::ldb_B_offset(int ld_block2, bool is_tail) const
+        noexcept {
     return (is_tail) ? brg.typesize_B * brg.ldb_tail * brg.ld_step
                      : brg.typesize_B * ld_block2 * brg.ld_block * brg.ld_step;
 }
-int jit_brgemm_kernel_base_t::ldb_C_offset(int ld_block2, bool is_tail) {
+int jit_brgemm_kernel_base_t::ldb_C_offset(int ld_block2, bool is_tail) const
+        noexcept {
     return (is_tail) ? brg.typesize_C * brg.ldb_tail
                      : brg.typesize_C * ld_block2 * brg.ld_block;
 }
-int jit_brgemm_kernel_base_t::ldb_D_offset(int ld_block2, bool is_tail) {
+int jit_brgemm_kernel_base_t::ldb_D_offset(int ld_block2, bool is_tail) const
+        noexcept {
     return (is_tail) ? brg.typesize_D * brg.ldb_tail
                      : brg.typesize_D * ld_block2 * brg.ld_block;
 }
 
-int jit_brgemm_kernel_base_t::bdb_A_offset(int bd_block2) {
+int jit_brgemm_kernel_base_t::bdb_A_offset(int bd_block2) const noexcept {
     return brg.typesize_A * bd_block2 * brg.bd_block * brg.LDA;
 }
-int jit_brgemm_kernel_base_t::bdb_C_offset(int bd_block2) {
+int jit_brgemm_kernel_base_t::bdb_C_offset(int bd_block2) const noexcept {
     return brg.typesize_C * bd_block2 * brg.bd_block * brg.LDC;
 }
-int jit_brgemm_kernel_base_t::bdb_D_offset(int bd_block2) {
+int jit_brgemm_kernel_base_t::bdb_D_offset(int bd_block2) const noexcept {
     return brg.typesize_D * bd_block2 * brg.bd_block * brg.LDD;
 }
 
-int jit_brgemm_kernel_base_t::bias_offset(int ld, bool is_tail) {
+int jit_brgemm_kernel_base_t::bias_offset(int ld, bool is_tail) const noexcept {
     return (is_tail) ? brg.typesize_bias * brg.ldb_tail
                      : brg.typesize_bias * ld * brg.ld_block;
 }
 
-int jit_brgemm_kernel_base_t::compensations_offset(int ld, bool is_tail) {
+int jit_brgemm_kernel_base_t::oc_logical_offset(int ld, bool is_tail) const
+        noexcept {
+    return (is_tail) ? brg.ldb_tail : ld * brg.ld_block;
+}
+
+int jit_brgemm_kernel_base_t::compensations_offset(int ld, bool is_tail) const
+        noexcept {
     return (is_tail) ? sizeof(int32_t) * brg.ldb_tail
                      : sizeof(int32_t) * ld * brg.ld_block;
 }
 
-int jit_brgemm_kernel_base_t::scales_offset(int ld, bool is_tail) {
+int jit_brgemm_kernel_base_t::scales_offset(int ld, bool is_tail) const
+        noexcept {
     return (is_tail) ? brg.is_oc_scale * sizeof(float) * brg.ldb_tail
                      : brg.is_oc_scale * sizeof(float) * ld * brg.ld_block;
 }
 Xbyak::Zmm jit_brgemm_kernel_base_t::zmm_mask(const Xbyak::Zmm zmm_in,
-        bool mask_flag, bool store, Xbyak::Opmask ktail_mask) {
+        bool mask_flag, bool store, Xbyak::Opmask ktail_mask) const {
     return mask_flag ? (store ? zmm_in | ktail_mask : zmm_in | ktail_mask | T_z)
                      : zmm_in;
 }
 
 Xbyak::Ymm jit_brgemm_kernel_base_t::ymm_mask(const Xbyak::Ymm ymm_in,
-        bool mask_flag, bool store, Xbyak::Opmask ktail_mask) {
+        bool mask_flag, bool store, Xbyak::Opmask ktail_mask) const {
     return mask_flag ? (store ? ymm_in | ktail_mask : ymm_in | ktail_mask | T_z)
                      : ymm_in;
 }
@@ -320,6 +356,8 @@ void jit_brgemm_kernel_base_t::cvt2ps(data_type_t type_in,
 void jit_brgemm_kernel_base_t::read_params() {
     Label label_done;
 
+    if (brg.with_binary) mov(ptr[rsp + abi_param1_offs_], param1);
+
     if (brg.type == brgemm_addr) {
         mov(reg_addr_batch, ptr[param1 + GET_OFF(batch)]);
     } else {
@@ -359,6 +397,10 @@ void jit_brgemm_kernel_base_t::read_params() {
         mov(reg_scales, ptr[param1 + GET_OFF(ptr_scales)]);
         mov(ptr[rsp + reg_scales_offs_], reg_scales);
     }
+    if (with_binary_per_oc_bcast_) {
+        mov(reg_binary_postops_oc_l, ptr[param1 + GET_OFF(oc_logical_off)]);
+        mov(ptr[rsp + reg_binary_postops_oc_l_offs_], reg_binary_postops_oc_l);
+    }
 
     mov(reg_do_post_ops, ptr[param1 + GET_OFF(do_post_ops)]);
     mov(ptr[rsp + reg_do_post_ops_offs_], reg_do_post_ops);
@@ -427,6 +469,63 @@ void jit_brgemm_kernel_base_t::apply_alpha_beta(
     }
 }
 
+void jit_brgemm_kernel_base_t::apply_post_ops(
+        int bd_block, int ld_block2, bool is_ld_tail) {
+
+    if (brg.with_sum) {
+        const auto sum_injector = [=]() {
+            const float *p_sum_scale = &brg.sum_scale;
+            if (*p_sum_scale != 1.f)
+                mov(reg_ptr_sum_scale, (size_t)p_sum_scale);
+            const auto k_mask = (!is_ld_tail) ? ld_full_mask : ld_tail_mask;
+
+            for (int bd = 0; bd < bd_block; bd++) {
+                for (int ld = 0; ld < ld_block2; ld++) {
+                    const auto zmm = accm(ld_block2, bd, ld);
+                    const auto addr = ptr[reg_aux_D + D_offset(bd, ld)];
+                    const auto zmm_prev_dst = Xbyak::Zmm(0);
+                    cvt2ps(brg.dt_d, zmm_prev_dst, addr, true, false, k_mask);
+                    if (*p_sum_scale == 1.f)
+                        vaddps(zmm, zmm_prev_dst);
+                    else
+                        vfmadd231ps(
+                                zmm, zmm_prev_dst, zword_b[reg_ptr_sum_scale]);
+                }
+            }
+        };
+
+        postops_injector_->set_lambda_injector(
+                primitive_kind::sum, sum_injector);
+    }
+
+    binary_injector::rhs_arg_dynamic_params_t rhs_arg_params;
+
+    const injector_utils::conditional_register_preserve_guard_t register_guard(
+            brg.with_binary, this, {param1});
+    const auto guard_space = register_guard.stack_space_occupied();
+    if (brg.with_binary) {
+        mov(param1, ptr[rsp + abi_param1_offs_ + guard_space]);
+
+        if (with_binary_per_oc_bcast_) {
+            mov(reg_aux_binary_postops_oc_l,
+                    ptr[rsp + reg_aux_binary_postops_oc_l_offs_ + guard_space]);
+
+            for_(int bd = 0; bd < bd_block; bd++)
+            for (int ld = 0; ld < ld_block2; ld++) {
+                const auto zmm_idx = accm(ld_block2, bd, ld).getIdx();
+
+                rhs_arg_params.vmm_idx_to_oc_off_oprnd.emplace(
+                        zmm_idx, reg_aux_binary_postops_oc_l);
+                rhs_arg_params.vmm_idx_to_oc_elem_off_val.emplace(
+                        zmm_idx, oc_logical_offset(ld));
+                if (is_ld_tail) rhs_arg_params.vmm_tail_idx_.emplace(zmm_idx);
+            }
+        }
+    }
+    postops_injector_->compute_vector_range(
+            32 - bd_block * ld_block2, 32, rhs_arg_params);
+}
+
 void jit_brgemm_kernel_base_t::store_accumulators_apply_post_ops(
         int bd_block, int ld_block2, bool is_ld_tail) {
     auto k_mask = (!is_ld_tail) ? ld_full_mask : ld_tail_mask;
@@ -478,38 +577,7 @@ void jit_brgemm_kernel_base_t::store_accumulators_apply_post_ops(
         }
     }
 
-    bool sum_before_eltwise = false;
-    if (brg.with_sum) {
-        const auto &p = brg.attr->post_ops_;
-        const int sum_idx = p.find(primitive_kind::sum);
-        sum_before_eltwise
-                = (sum_idx == 0) && p.contain(primitive_kind::eltwise, 1);
-    }
-
-    if (brg.with_eltwise && !sum_before_eltwise)
-        eltwise_injector_->compute_vector_range(32 - bd_block * ld_block2, 32);
-
-    if (brg.with_sum) {
-        const float *p_sum_scale = &brg.sum_scale;
-        if (*p_sum_scale != 1.f) mov(reg_ptr_sum_scale, (size_t)p_sum_scale);
-
-        for (int bd = 0; bd < bd_block; bd++) {
-            for (int ld = 0; ld < ld_block2; ld++) {
-                auto zmm = accm(ld_block2, bd, ld);
-                auto addr = ptr[reg_aux_D + D_offset(bd, ld)];
-
-                auto zmm_prev_dst = Xbyak::Zmm(0);
-                cvt2ps(brg.dt_d, zmm_prev_dst, addr, true, false, k_mask);
-                if (*p_sum_scale == 1.f)
-                    vaddps(zmm, zmm_prev_dst);
-                else
-                    vfmadd231ps(zmm, zmm_prev_dst, zword_b[reg_ptr_sum_scale]);
-            }
-        }
-    }
-
-    if (brg.with_eltwise && sum_before_eltwise)
-        eltwise_injector_->compute_vector_range(32 - bd_block * ld_block2, 32);
+    if (postops_injector_) apply_post_ops(bd_block, ld_block2, is_ld_tail);
 
     const bool dt_requires_saturation
             = one_of(brg.dt_d, data_type::u8, data_type::s8, data_type::s32);
@@ -620,19 +688,29 @@ void jit_brgemm_kernel_base_t::store_accumulators(
                         if (apply_post_ops) {
                             store_accumulators_apply_post_ops(
                                     brg.bd_block, 1, is_ld_tail);
-                            if (brg.with_bias && ldb < ld_block2 - 1) {
-                                mov(reg_aux_bias,
-                                        ptr[rsp + reg_aux_bias_offs_]);
-                                add(reg_aux_bias, bias_offset(1));
-                                mov(ptr[rsp + reg_aux_bias_offs_],
-                                        reg_aux_bias);
-                            }
-                            if (brg.with_scales && ldb < ld_block2 - 1) {
-                                mov(reg_aux_scales,
-                                        ptr[rsp + reg_aux_scales_offs_]);
-                                add(reg_aux_scales, scales_offset(1));
-                                mov(ptr[rsp + reg_aux_scales_offs_],
-                                        reg_aux_scales);
+                            if (ldb < ld_block2 - 1) {
+                                if (brg.with_bias) {
+                                    mov(reg_aux_bias,
+                                            ptr[rsp + reg_aux_bias_offs_]);
+                                    add(reg_aux_bias, bias_offset(1));
+                                    mov(ptr[rsp + reg_aux_bias_offs_],
+                                            reg_aux_bias);
+                                }
+                                if (brg.with_scales) {
+                                    mov(reg_aux_scales,
+                                            ptr[rsp + reg_aux_scales_offs_]);
+                                    add(reg_aux_scales, scales_offset(1));
+                                    mov(ptr[rsp + reg_aux_scales_offs_],
+                                            reg_aux_scales);
+                                }
+                                if (with_binary_per_oc_bcast_) {
+                                    mov(reg_aux_binary_postops_oc_l,
+                                            ptr[rsp + reg_aux_binary_postops_oc_l_offs_]);
+                                    add(reg_aux_binary_postops_oc_l,
+                                            oc_logical_offset(1));
+                                    mov(ptr[rsp + reg_aux_binary_postops_oc_l_offs_],
+                                            reg_aux_binary_postops_oc_l);
+                                }
                             }
                             mov(reg_buf, ptr[rsp + reg_buf_offs_]);
                             add(reg_aux_D, ldb_D_offset(1));
@@ -652,20 +730,33 @@ void jit_brgemm_kernel_base_t::store_accumulators(
                     sub(reg_aux_D, ldb_D_offset(ld_block2));
                     add(reg_aux_D, bdb_D_offset(1));
 
-                    if ((brg.with_bias || brg.with_scales) && ld_block2 > 1) {
+                    if (ld_block2 > 1) {
+                        bool post_processed = false;
                         if (brg.with_bias) {
+                            post_processed = true;
                             mov(reg_aux_bias, ptr[rsp + reg_aux_bias_offs_]);
                             sub(reg_aux_bias, bias_offset(ld_block2 - 1));
                             mov(ptr[rsp + reg_aux_bias_offs_], reg_aux_bias);
                         }
                         if (brg.with_scales) {
+                            post_processed = true;
                             mov(reg_aux_scales,
                                     ptr[rsp + reg_aux_scales_offs_]);
                             sub(reg_aux_scales, scales_offset(ld_block2 - 1));
                             mov(ptr[rsp + reg_aux_scales_offs_],
                                     reg_aux_scales);
                         }
-                        mov(reg_buf, ptr[rsp + reg_buf_offs_]);
+                        if (with_binary_per_oc_bcast_) {
+                            post_processed = true;
+                            mov(reg_aux_binary_postops_oc_l,
+                                    ptr[rsp + reg_aux_binary_postops_oc_l_offs_]);
+                            sub(reg_aux_binary_postops_oc_l,
+                                    oc_logical_offset(ld_block2 - 1));
+                            mov(ptr[rsp + reg_aux_binary_postops_oc_l_offs_],
+                                    reg_aux_binary_postops_oc_l);
+                        }
+                        if (post_processed)
+                            mov(reg_buf, ptr[rsp + reg_buf_offs_]);
                     }
                 }
             }
@@ -1000,6 +1091,15 @@ void jit_brgemm_kernel_base_t::ldb_loop(int bd_block2, bool is_bdb_tail,
                               : scales_offset(ld_block2));
             mov(ptr[rsp + reg_aux_scales_offs_], reg_aux_scales);
         }
+        if (with_binary_per_oc_bcast_) {
+            mov(reg_aux_binary_postops_oc_l,
+                    ptr[rsp + reg_aux_binary_postops_oc_l_offs_]);
+            add(reg_aux_binary_postops_oc_l,
+                    (is_tail) ? oc_logical_offset(1, true)
+                              : oc_logical_offset(ld_block2));
+            mov(ptr[rsp + reg_aux_binary_postops_oc_l_offs_],
+                    reg_aux_binary_postops_oc_l);
+        }
     };
 
     Label ldb_loop_label;
@@ -1021,6 +1121,12 @@ void jit_brgemm_kernel_base_t::ldb_loop(int bd_block2, bool is_bdb_tail,
             mov(reg_scales, ptr[rsp + reg_scales_offs_]);
             mov(ptr[rsp + reg_aux_scales_offs_], reg_scales);
         }
+        if (with_binary_per_oc_bcast_) {
+            mov(reg_binary_postops_oc_l,
+                    ptr[rsp + reg_binary_postops_oc_l_offs_]);
+            mov(ptr[rsp + reg_aux_binary_postops_oc_l_offs_],
+                    reg_binary_postops_oc_l);
+        }
     }
 
     auto ld_loop_body = [=](int vpad) {
@@ -1378,7 +1484,7 @@ void jit_brgemm_kernel_base_t::generate() {
 
     postamble();
 
-    if (brg.with_eltwise) eltwise_injector_->prepare_table();
+    if (brg.with_eltwise) postops_injector_->prepare_table();
 }
 
 brgemm_kernel_t::brgemm_kernel_t(const brgemm_t abrd) {
diff --git a/src/cpu/x64/jit_brgemm_1x1_conv.cpp b/src/cpu/x64/jit_brgemm_1x1_conv.cpp
index d0a4721b5..a5ab3ccd7 100644
--- a/src/cpu/x64/jit_brgemm_1x1_conv.cpp
+++ b/src/cpu/x64/jit_brgemm_1x1_conv.cpp
@@ -14,12 +14,12 @@
 * limitations under the License.
 *******************************************************************************/
 
+#include "cpu/x64/jit_brgemm_1x1_conv.hpp"
 #include "common/c_types_map.hpp"
 #include "common/dnnl_thread.hpp"
 #include "common/type_helpers.hpp"
 #include "common/utils.hpp"
-
-#include "cpu/x64/jit_brgemm_1x1_conv.hpp"
+#include "cpu/x64/injectors/jit_uni_binary_injector.hpp"
 
 namespace dnnl {
 namespace impl {
@@ -109,10 +109,10 @@ brgemm_1x1_convolution_fwd_t<isa, src_type, wei_type, dst_type>::pd_t::init(
         brgattr.max_bottom_vpad = jcp_.max_vpad;
         brgattr.wary_tail_read = false;
         CHECK(brgemm_desc_set_attr(&brg, brgattr));
-        auto dt_d = dst_type;
         auto LDD = jcp_.oc_without_padding;
         brg.with_sum = with_sum;
-        CHECK(brgemm_desc_set_postops(&brg, attr(), dt_d, LDD, jcp_.bia_dt));
+        CHECK(brgemm_desc_set_postops(
+                &brg, &dst_md_, attr(), LDD, jcp_.bia_dt));
     }
 
     auto scratchpad = scratchpad_registry().registrar();
@@ -209,6 +209,9 @@ void brgemm_1x1_convolution_fwd_t<isa, src_type, wei_type, dst_type>::exec_ker(
     dst_data_t *const __restrict dst = CTX_OUT_MEM(dst_data_t *, DNNL_ARG_DST);
 
     const float *oscales = pd()->attr()->output_scales_.scales_;
+    const auto post_ops_binary_rhs_arg_vec
+            = binary_injector::prepare_binary_args(
+                    pd()->attr()->post_ops_, ctx);
 
     const auto &jcp = pd()->jcp_;
     auto ndims = pd()->ndims();
@@ -263,9 +266,14 @@ void brgemm_1x1_convolution_fwd_t<isa, src_type, wei_type, dst_type>::exec_ker(
         }
 
         if (do_postops) {
+            const brgemm_post_ops_data_t post_ops_data {
+                    static_cast<const void *>(bias_w),
+                    &oscales[jcp.is_oc_scale * g_oc],
+                    post_ops_binary_rhs_arg_vec.data(),
+                    static_cast<size_t>(g_oc)};
+
             brgemm_kernel_execute_postops(brg_ker, n_ic_blocks, brg_batch,
-                    (void *)ptr_C, (void *)ptr_D, (void *)bias_w,
-                    &oscales[jcp.is_oc_scale * g_oc]);
+                    (void *)ptr_C, (void *)ptr_D, post_ops_data);
         } else {
             brgemm_kernel_execute(
                     brg_ker, n_ic_blocks, brg_batch, (void *)ptr_C);
diff --git a/src/cpu/x64/jit_brgemm_conv.cpp b/src/cpu/x64/jit_brgemm_conv.cpp
index 284c094d2..7768f4fb0 100644
--- a/src/cpu/x64/jit_brgemm_conv.cpp
+++ b/src/cpu/x64/jit_brgemm_conv.cpp
@@ -14,12 +14,12 @@
 * limitations under the License.
 *******************************************************************************/
 
+#include "cpu/x64/jit_brgemm_conv.hpp"
 #include "common/c_types_map.hpp"
 #include "common/dnnl_thread.hpp"
 #include "common/type_helpers.hpp"
 #include "common/utils.hpp"
-
-#include "cpu/x64/jit_brgemm_conv.hpp"
+#include "cpu/x64/injectors/jit_uni_binary_injector.hpp"
 
 namespace dnnl {
 namespace impl {
@@ -137,11 +137,10 @@ brgemm_convolution_fwd_t<isa, src_type, wei_type, dst_type>::pd_t::init(
             brgattr.wary_tail_read = false;
             CHECK(brgemm_desc_set_attr(&brg, brgattr));
 
-            auto dt_d = dst_type;
             auto LDD = jcp_.oc_without_padding;
             brg.with_sum = with_sum;
             CHECK(brgemm_desc_set_postops(
-                    &brg, attr(), dt_d, LDD, jcp_.bia_dt));
+                    &brg, &dst_md_, attr(), LDD, jcp_.bia_dt));
         }
     }
 
@@ -658,13 +657,18 @@ template <cpu_isa_t isa, data_type_t src_type, data_type_t wei_type,
 void brgemm_convolution_fwd_t<isa, src_type, wei_type,
         dst_type>::call_brgemm_kernel(brgemm_kernel_t *brg_ker, int batch_size,
         brgemm_batch_element_t *const __restrict brg_batch, char *ptr_C,
-        dst_data_t *ptr_D, const char *bias_w, int g_oc,
-        bool do_postops) const {
+        dst_data_t *ptr_D, const char *bias_w, int g_oc, bool do_postops,
+        const void *binary_post_ops_rhs) const {
     const auto &jcp = pd()->jcp_;
-    if (do_postops)
-        brgemm_kernel_execute_postops(brg_ker, batch_size, brg_batch, ptr_C,
-                ptr_D, (void *)bias_w, &oscales[jcp.is_oc_scale * g_oc]);
-    else
+    if (do_postops) {
+        const brgemm_post_ops_data_t post_ops_data {
+                static_cast<const void *>(bias_w),
+                &oscales[jcp.is_oc_scale * g_oc], binary_post_ops_rhs,
+                static_cast<size_t>(g_oc)};
+
+        brgemm_kernel_execute_postops(
+                brg_ker, batch_size, brg_batch, ptr_C, ptr_D, post_ops_data);
+    } else
         brgemm_kernel_execute(brg_ker, batch_size, brg_batch, ptr_C);
 }
 
@@ -762,6 +766,9 @@ void brgemm_convolution_fwd_t<isa, src_type, wei_type,
             = CTX_IN_MEM(const char *, DNNL_ARG_BIAS); \
     dst_data_t *const __restrict dst \
             = CTX_OUT_MEM(dst_data_t *, DNNL_ARG_DST); \
+    const auto post_ops_binary_rhs_arg_vec \
+            = binary_injector::prepare_binary_args( \
+                    pd()->attr()->post_ops_, ctx); \
     const int oc = ocb * jcp.oc_block; \
     const int g_oc = g * jcp.oc + oc; \
     const int icb = icc * jcp.nb_ic_blocking; \
@@ -849,7 +856,7 @@ void brgemm_convolution_fwd_t<isa, src_type, wei_type, dst_type>::ker_base(
         }
 
         call_brgemm_kernel(brg_ker, k_l * n_ic_blocks, brg_batch, ptr_C, ptr_D,
-                bias_w, g_oc, do_postops);
+                bias_w, g_oc, do_postops, post_ops_binary_rhs_arg_vec.data());
     };
 
     const auto kdhw_loop = [&]() {
@@ -1030,7 +1037,7 @@ void brgemm_convolution_fwd_t<isa, src_type, wei_type, dst_type>::ker_trans(
         }
 
         call_brgemm_kernel(brg_ker, k_l * n_ic_blocks, brg_batch, ptr_C, ptr_D,
-                bias_w, g_oc, do_postops);
+                bias_w, g_oc, do_postops, post_ops_binary_rhs_arg_vec.data());
     };
 
     const auto kdhw_loop = [&]() {
@@ -1160,7 +1167,7 @@ void brgemm_convolution_fwd_t<isa, src_type, wei_type, dst_type>::ker_vpad(
         }
 
         call_brgemm_kernel(brg_ker, k_l * n_ic_blocks, brg_batch, ptr_C, ptr_D,
-                bias_w, g_oc, do_postops);
+                bias_w, g_oc, do_postops, post_ops_binary_rhs_arg_vec.data());
     };
 
     const auto kdhw_loop = [&]() {
diff --git a/src/cpu/x64/jit_brgemm_conv.hpp b/src/cpu/x64/jit_brgemm_conv.hpp
index 1f11d557e..4d9f0debb 100644
--- a/src/cpu/x64/jit_brgemm_conv.hpp
+++ b/src/cpu/x64/jit_brgemm_conv.hpp
@@ -133,8 +133,8 @@ private:
 
     void call_brgemm_kernel(brgemm_kernel_t *brg_ker, int batch_size,
             brgemm_batch_element_t *const __restrict brg_batch, char *ptr_C,
-            dst_data_t *ptr_D, const char *bias_w, int g_oc,
-            bool do_postops) const;
+            dst_data_t *ptr_D, const char *bias_w, int g_oc, bool do_postops,
+            const void *binary_post_ops_rhs) const;
 
     void maybe_conv_inp(int ithr, const src_data_t *__restrict src,
             src_data_t *__restrict inp_buffer,
diff --git a/src/cpu/x64/jit_brgemm_conv_utils.cpp b/src/cpu/x64/jit_brgemm_conv_utils.cpp
index dc5560406..8e867e0ca 100644
--- a/src/cpu/x64/jit_brgemm_conv_utils.cpp
+++ b/src/cpu/x64/jit_brgemm_conv_utils.cpp
@@ -24,6 +24,7 @@
 #include "common/utils.hpp"
 
 #include "cpu/x64/cpu_isa_traits.hpp"
+#include "cpu/x64/injectors/jit_uni_postops_injector.hpp"
 #include "cpu/x64/jit_brgemm_conv_utils.hpp"
 #include "cpu/x64/jit_generator.hpp"
 
@@ -56,23 +57,17 @@ inline status_t init_tag(format_tag_t &tag, memory_desc_t &md,
     return status::success;
 }
 
-bool post_ops_ok(jit_brgemm_conv_conf_t &jcp, const primitive_attr_t &attr) {
-    using namespace primitive_kind;
-    const auto &p = attr.post_ops_;
-
-    auto is_eltwise = [&](int idx) { return p.entry_[idx].is_eltwise(); };
+bool post_ops_ok(jit_brgemm_conv_conf_t &jcp, const primitive_attr_t &attr,
+        const memory_desc_wrapper &dst_d) {
+    using namespace injector;
 
-    switch (p.len()) {
-        case 0: return true;
-        case 1: return is_eltwise(0) || p.contain(sum, 0);
-        case 2:
-            return (p.contain(sum, 0) && is_eltwise(1))
-                    || (one_of(jcp.src_dt, u8, s8) && p.contain(sum, 1)
-                            && is_eltwise(0));
-        default: return false;
-    }
+    const auto &post_ops = attr.post_ops_;
 
-    return false;
+    return injector::post_ops_ok(post_ops_ok_args_t(avx512_common,
+            {sum, eltwise, binary}, post_ops, &dst_d,
+            true /*sum_at_pos_0_only*/, false /*sum_requires_scale_one*/,
+            {broadcasting_strategy_t::per_oc,
+                    broadcasting_strategy_t::scalar}));
 }
 
 status_t init_jcp(jit_brgemm_conv_conf_t &jcp, const convolution_desc_t &cd,
@@ -164,19 +159,21 @@ status_t init_jcp(jit_brgemm_conv_conf_t &jcp, const convolution_desc_t &cd,
     jcp.acc_dsz = types::data_type_size(jcp.acc_dt);
     jcp.bia_dsz = jcp.with_bias ? types::data_type_size(jcp.bia_dt) : 0;
 
+    if (!post_ops_ok(jcp, attr, dst_d)) return status::unimplemented;
+
     jcp.simd_w = cpu_isa_traits<avx512_common>::vlen / jcp.src_dsz;
     const auto &p = attr.post_ops_;
     jcp.with_sum = p.find(primitive_kind::sum) != -1;
     const int eltwise_ind = p.find(primitive_kind::eltwise);
     jcp.with_eltwise = eltwise_ind != -1;
-    if (jcp.with_eltwise) jcp.eltwise = p.entry_[eltwise_ind].eltwise;
+    const int binary_ind = p.find(primitive_kind::binary);
+    jcp.with_binary = binary_ind != -1;
+
     if (jcp.with_bias) {
         if (bias_d.format_kind() == format_kind::any)
             CHECK(memory_desc_init_by_tag(bias_md, x));
     }
 
-    if (!post_ops_ok(jcp, attr)) return status::unimplemented;
-
     jcp.nthr = nthreads;
 
     return status::success;
@@ -466,7 +463,8 @@ struct brg_blocking_t {
 };
 
 int get_brgemm_ur(const jit_brgemm_conv_conf_t &jcp, cpu_isa_t isa,
-        const brg_blocking_t &brgb, const primitive_attr_t *attr, bool is_1x1) {
+        const brg_blocking_t &brgb, const memory_desc_t &dst_md,
+        const primitive_attr_t *attr, bool is_1x1) {
     // Simulation of brgemm_desc init
     brgemm_t brg;
     const auto ic_block = brgb.ic_block;
@@ -537,10 +535,9 @@ int get_brgemm_ur(const jit_brgemm_conv_conf_t &jcp, cpu_isa_t isa,
                     status = brgemm_desc_set_attr(&brg, brgattr);
                     if (status != success) break;
 
-                    auto dt_d = jcp.dst_dt;
                     brg.with_sum = jcp.with_sum;
                     status = brgemm_desc_set_postops(
-                            &brg, attr, dt_d, LDD, jcp.bia_dt);
+                            &brg, &dst_md, attr, LDD, jcp.bia_dt);
                     if (status != success) break;
                 }
                 if (status != success) break;
@@ -756,7 +753,8 @@ status_t init_conf(jit_brgemm_conv_conf_t &jcp, cpu_isa_t isa,
 
             calc_blocks(jcp, cur_brgb);
             const bool is_1x1 = false;
-            const auto ur = get_brgemm_ur(jcp, isa, cur_brgb, &attr, is_1x1);
+            const auto ur
+                    = get_brgemm_ur(jcp, isa, cur_brgb, dst_md, &attr, is_1x1);
             if (ur == 0) continue;
 
             const auto oc_block_disb
@@ -1073,7 +1071,8 @@ status_t init_1x1_conf(jit_brgemm_conv_conf_t &jcp, cpu_isa_t isa,
         cur_brgb.nb_oc = utils::div_up(jcp.oc, cur_brgb.oc_block);
         calc_blocks(jcp, cur_brgb);
         const bool is_1x1 = true;
-        const auto ur = get_brgemm_ur(jcp, isa, cur_brgb, &attr, is_1x1);
+        const auto ur
+                = get_brgemm_ur(jcp, isa, cur_brgb, dst_md, &attr, is_1x1);
         if (ur == 0) continue;
 
         const auto oc_block_disb
diff --git a/src/cpu/x64/jit_brgemm_inner_product.cpp b/src/cpu/x64/jit_brgemm_inner_product.cpp
index 93fb7a351..dfd93a27d 100644
--- a/src/cpu/x64/jit_brgemm_inner_product.cpp
+++ b/src/cpu/x64/jit_brgemm_inner_product.cpp
@@ -21,6 +21,7 @@
 
 #include "cpu/x64/amx_tile_configure.hpp"
 #include "cpu/x64/cpu_barrier.hpp"
+#include "cpu/x64/injectors/jit_uni_binary_injector.hpp"
 #include "cpu/x64/jit_brgemm_inner_product.hpp"
 
 namespace dnnl {
@@ -46,6 +47,9 @@ void brgemm_inner_product_fwd_t<isa>::execute_forward(
     auto weights = CTX_IN_MEM(const char *, DNNL_ARG_WEIGHTS);
     auto bias = CTX_IN_MEM(const char *, DNNL_ARG_BIAS);
     auto dst = CTX_OUT_MEM(char *, DNNL_ARG_DST);
+    const auto post_ops_binary_rhs_arg_vec
+            = binary_injector::prepare_binary_args(
+                    pd()->attr()->post_ops_, ctx);
 
     memory_tracking::grantor_t scratchpad = ctx.get_scratchpad_grantor();
     const memory_desc_wrapper src_d(pd()->src_md());
@@ -130,12 +134,21 @@ void brgemm_inner_product_fwd_t<isa>::execute_forward(
             auto ptr_C = (jbgp.use_buffer) ? c_buffer : ptr_D;
             if (are_post_ops_applicable && icc == ic_chunks - 1
                     && !is_ic_tail) {
+                void *scratch = is_amx
+                        ? static_cast<void *>(wsp_tile)
+                        : (jbgp.signed_input ? static_cast<void *>(
+                                   const_cast<int *>(&compensation[oc]))
+                                             : nullptr);
+
+                const brgemm_post_ops_data_t post_ops_data {
+                        static_cast<const void *>(ptr_bias),
+                        &oscales[jbgp.is_oc_scale * oc],
+                        post_ops_binary_rhs_arg_vec.data(),
+                        static_cast<size_t>(oc)};
+
                 brgemm_kernel_execute_postops(brg_kernel, gemm_batch,
-                        addr_batch, (void *)ptr_C, (void *)ptr_D,
-                        (void *)ptr_bias, &oscales[jbgp.is_oc_scale * oc],
-                        is_amx ? (void *)wsp_tile
-                               : (jbgp.signed_input ? (void *)&compensation[oc]
-                                                    : nullptr));
+                        addr_batch, (void *)ptr_C, (void *)ptr_D, post_ops_data,
+                        scratch);
             } else {
                 brgemm_kernel_execute(brg_kernel, gemm_batch, addr_batch,
                         (void *)ptr_C, is_amx ? (void *)wsp_tile : nullptr);
@@ -161,12 +174,20 @@ void brgemm_inner_product_fwd_t<isa>::execute_forward(
             auto ptr_D = dst + get_blk_off(dst_d, jbgp.dst_dt, n, oc);
             auto ptr_C = (jbgp.use_buffer) ? c_buffer : ptr_D;
             if (are_post_ops_applicable && icc == ic_chunks - 1) {
-                brgemm_kernel_execute_postops(brg_kernel_ic_tail, 1, addr_batch,
-                        (void *)ptr_C, (void *)ptr_D, (void *)ptr_bias,
+                void *scratch = is_amx
+                        ? static_cast<void *>(wsp_tile)
+                        : (jbgp.signed_input ? static_cast<void *>(
+                                   const_cast<int *>(&compensation[oc]))
+                                             : nullptr);
+
+                const brgemm_post_ops_data_t post_ops_data {
+                        static_cast<const void *>(ptr_bias),
                         &oscales[jbgp.is_oc_scale * oc],
-                        is_amx ? (void *)wsp_tile
-                               : (jbgp.signed_input ? (void *)&compensation[oc]
-                                                    : nullptr));
+                        post_ops_binary_rhs_arg_vec.data(),
+                        static_cast<size_t>(oc)};
+
+                brgemm_kernel_execute_postops(brg_kernel_ic_tail, 1, addr_batch,
+                        (void *)ptr_C, (void *)ptr_D, post_ops_data, scratch);
             } else {
                 brgemm_kernel_execute(brg_kernel_ic_tail, 1, addr_batch,
                         (void *)ptr_C, is_amx ? (void *)wsp_tile : nullptr);
@@ -373,9 +394,12 @@ void brgemm_inner_product_bwd_data_t<isa>::execute_backward_data(
             if (jbgp.use_buffer && occ == oc_chunks - 1 && !is_oc_tail) {
                 auto ptr_D = diff_src
                         + get_blk_off(diff_src_d, jbgp.src_dt, n, ic);
+                void *scratch
+                        = is_amx ? static_cast<void *>(wsp_tile) : nullptr;
+
                 brgemm_kernel_execute_postops(brg_kernel, nb_oc_b, addr_batch,
-                        (void *)c_buffer, (void *)ptr_D, nullptr, nullptr,
-                        is_amx ? (void *)wsp_tile : nullptr);
+                        (void *)c_buffer, (void *)ptr_D, {}, scratch);
+
             } else {
                 char *ptr_C = (jbgp.use_buffer) ? c_buffer
                                                 : (char *)diff_src
@@ -410,9 +434,12 @@ void brgemm_inner_product_bwd_data_t<isa>::execute_backward_data(
             if (jbgp.use_buffer && occ == oc_chunks - 1) {
                 auto ptr_D = diff_src
                         + get_blk_off(diff_src_d, jbgp.src_dt, n, ic);
+                void *scratch
+                        = is_amx ? static_cast<void *>(wsp_tile) : nullptr;
+
                 brgemm_kernel_execute_postops(brg_kernel_oc_tail, 1, addr_batch,
-                        (void *)c_buffer, (void *)ptr_D, nullptr, nullptr,
-                        is_amx ? (void *)wsp_tile : nullptr);
+                        (void *)c_buffer, (void *)ptr_D, {}, scratch);
+
             } else {
                 char *ptr_C = (jbgp.use_buffer) ? c_buffer
                                                 : (char *)diff_src
diff --git a/src/cpu/x64/jit_brgemm_inner_product.hpp b/src/cpu/x64/jit_brgemm_inner_product.hpp
index afc8c6ba0..e492cff22 100644
--- a/src/cpu/x64/jit_brgemm_inner_product.hpp
+++ b/src/cpu/x64/jit_brgemm_inner_product.hpp
@@ -133,7 +133,7 @@ struct brgemm_inner_product_fwd_t : public primitive_t {
 
                 auto LDD = jbgp_.oc_without_padding;
                 CHECK(brgemm_desc_set_postops(
-                        &brg, attr(), jbgp_.dst_dt, LDD, jbgp_.bia_dt));
+                        &brg, &dst_md_, attr(), LDD, jbgp_.bia_dt));
                 if (isa == avx512_core_bf16_amx_int8
                         || isa == avx512_core_bf16_amx_bf16) {
                     brgemm_attr_t brgattr;
@@ -252,7 +252,7 @@ struct brgemm_inner_product_bwd_data_t : public primitive_t {
 
                 auto LDD = jbgp_.ic_without_padding;
                 CHECK(brgemm_desc_set_postops(
-                        &brg, attr(), jbgp_.src_dt, LDD, jbgp_.bia_dt));
+                        &brg, &diff_src_md_, attr(), LDD, jbgp_.bia_dt));
                 if (isa == avx512_core_bf16_amx_bf16) {
                     brgemm_attr_t brgattr;
                     brgattr.max_bs = jbgp_.gemm_batch_size;
diff --git a/src/cpu/x64/jit_brgemm_inner_product_utils.cpp b/src/cpu/x64/jit_brgemm_inner_product_utils.cpp
index 8f3b3b674..5fb48759b 100644
--- a/src/cpu/x64/jit_brgemm_inner_product_utils.cpp
+++ b/src/cpu/x64/jit_brgemm_inner_product_utils.cpp
@@ -25,6 +25,7 @@
 
 #include "cpu/x64/cpu_barrier.hpp"
 #include "cpu/x64/cpu_isa_traits.hpp"
+#include "cpu/x64/injectors/jit_uni_postops_injector.hpp"
 #include "cpu/x64/jit_brgemm_inner_product_utils.hpp"
 #include "cpu/x64/jit_generator.hpp"
 
@@ -102,29 +103,21 @@ format_tag_t get_brgemm_ip_weights_tag(
     }
 }
 
-// TODO: add support of post-ops with multiple binary and eltwise execution
-bool post_ops_ok(
-        jit_brgemm_primitive_conf_t &jbgp, const primitive_attr_t &attr) {
-    using namespace primitive_kind;
-    const auto &p = attr.post_ops_;
-
-    auto is_eltwise = [&](int idx) { return p.entry_[idx].is_eltwise(); };
+bool post_ops_ok(jit_brgemm_primitive_conf_t &jbgp,
+        const primitive_attr_t &attr, const memory_desc_wrapper &dst_d) {
+    using namespace injector;
 
-    switch (p.len()) {
-        case 0: return true;
-        case 1: return is_eltwise(0) || p.contain(sum, 0);
-        case 2:
-            return (p.contain(sum, 0) && is_eltwise(1))
-                    || (one_of(jbgp.src_dt, u8, s8) && p.contain(sum, 1)
-                            && is_eltwise(0));
-        default: return false;
-    }
+    const auto &post_ops = attr.post_ops_;
 
-    return false;
+    return injector::post_ops_ok(post_ops_ok_args_t(avx512_common,
+            {sum, eltwise, binary}, post_ops, &dst_d,
+            true /*sum_at_pos_0_only*/, false /*sum_requires_scale_one*/,
+            {broadcasting_strategy_t::per_oc,
+                    broadcasting_strategy_t::scalar}));
 }
 
-status_t init_ip_conf_fwd(
-        jit_brgemm_primitive_conf_t &jbgp, const primitive_attr_t &attr) {
+status_t init_ip_conf_fwd(jit_brgemm_primitive_conf_t &jbgp,
+        const primitive_attr_t &attr, const memory_desc_wrapper &dst_d) {
     const bool is_amx_int8 = jbgp.isa == avx512_core_bf16_amx_int8;
     const bool is_amx_bf16 = jbgp.isa == avx512_core_bf16_amx_bf16;
     const bool is_int8 = one_of(jbgp.src_dt, u8, s8) && jbgp.wei_dt == s8;
@@ -132,8 +125,9 @@ status_t init_ip_conf_fwd(
     jbgp.with_sum = p.find(primitive_kind::sum) != -1;
     const int eltwise_ind = p.find(primitive_kind::eltwise);
     jbgp.with_eltwise = eltwise_ind != -1;
-    if (jbgp.with_eltwise) jbgp.eltwise = p.entry_[eltwise_ind].eltwise;
-    if (!post_ops_ok(jbgp, attr)) return status::unimplemented;
+    const int binary_ind = p.find(primitive_kind::binary);
+    jbgp.with_binary = binary_ind != -1;
+    if (!post_ops_ok(jbgp, attr, dst_d)) return status::unimplemented;
     if (jbgp.with_scales) {
         const auto &oscales = attr.output_scales_;
         jbgp.is_oc_scale = oscales.mask_ == 1 << 1;
@@ -595,7 +589,7 @@ status_t init_ip_conf(cpu_isa_t isa, jit_brgemm_primitive_conf_t &jbgp,
 
     switch (jbgp.prop_kind) {
         case forward_training:
-        case forward_inference: return init_ip_conf_fwd(jbgp, attr);
+        case forward_inference: return init_ip_conf_fwd(jbgp, attr, dst_d);
         case backward_data: return init_ip_conf_bwd_d(jbgp);
         case backward_weights: return init_ip_conf_bwd_w(jbgp);
         default: assert(!"invalid prop_kind"); return invalid_arguments;
diff --git a/src/cpu/x64/jit_brgemm_primitive_conf.hpp b/src/cpu/x64/jit_brgemm_primitive_conf.hpp
index 8f9b988d3..683801dfc 100644
--- a/src/cpu/x64/jit_brgemm_primitive_conf.hpp
+++ b/src/cpu/x64/jit_brgemm_primitive_conf.hpp
@@ -44,9 +44,9 @@ struct jit_brgemm_primitive_conf_t {
     bool with_bias;
     bool with_sum;
     bool with_eltwise;
+    bool with_binary;
     bool with_scales;
     bool signed_input;
-    post_ops_t::entry_t::eltwise_t eltwise;
     int nb_ic, ic_block;
     int nb_oc, oc_block;
     int nb_iw, iw_block;
diff --git a/src/cpu/x64/jit_primitive_conf.hpp b/src/cpu/x64/jit_primitive_conf.hpp
index ae2d1ad0a..340708277 100644
--- a/src/cpu/x64/jit_primitive_conf.hpp
+++ b/src/cpu/x64/jit_primitive_conf.hpp
@@ -792,8 +792,9 @@ struct jit_brgemm_conv_conf_t {
     bool with_bias;
     bool with_sum;
     bool with_eltwise;
+    bool with_binary;
+
     bool is_fused_conv;
-    post_ops_t::entry_t::eltwise_t eltwise;
     int nb_ic, ic_block;
     int nb_oc, oc_block;
     int nb_iw, iw_block;
diff --git a/src/cpu/x64/matmul/brgemm_matmul.cpp b/src/cpu/x64/matmul/brgemm_matmul.cpp
index b4eebf5e9..456c20638 100644
--- a/src/cpu/x64/matmul/brgemm_matmul.cpp
+++ b/src/cpu/x64/matmul/brgemm_matmul.cpp
@@ -23,6 +23,7 @@
 #include "cpu/cpu_primitive.hpp"
 
 #include "cpu/x64/amx_tile_configure.hpp"
+#include "cpu/x64/injectors/jit_uni_binary_injector.hpp"
 #include "cpu/x64/matmul/brgemm_matmul.hpp"
 
 namespace dnnl {
@@ -96,7 +97,7 @@ status_t brgemm_matmul_t<isa>::pd_t::init(engine_t *engine) {
 
         auto LDD = bgmmc_.N;
         CHECK(brgemm_desc_set_postops(
-                &brg, attr(), bgmmc_.dst_dt, LDD, bgmmc_.bia_dt));
+                &brg, &dst_md_, attr(), LDD, bgmmc_.bia_dt));
 
         if (isa == avx512_core_bf16_amx_int8) {
             brgemm_attr_t brgattr;
@@ -159,6 +160,10 @@ void brgemm_matmul_t<isa>::execute_body(const exec_ctx_t &ctx) const {
 
     const float *oscales = pd()->attr()->output_scales_.scales_;
 
+    const auto post_ops_binary_rhs_arg_vec
+            = binary_injector::prepare_binary_args(
+                    pd()->attr()->post_ops_, ctx);
+
     const auto &bgmmc = pd()->get_brgemm_matmul_conf();
     const size_t bia_dt_size
             = bgmmc.with_bias ? types::data_type_size(bgmmc.bia_dt) : 0;
@@ -283,13 +288,21 @@ void brgemm_matmul_t<isa>::execute_body(const exec_ctx_t &ctx) const {
             }
 
             if (are_post_ops_applicable && is_last_K_chunk && !is_K_tail) {
+                void *scratch = is_amx
+                        ? static_cast<void *>(wsp_tile)
+                        : (bgmmc.signed_input ? static_cast<void *>(
+                                   const_cast<int *>(&compensation[comp_idx]))
+                                              : nullptr);
+
+                const brgemm_post_ops_data_t post_ops_data {
+                        static_cast<const void *>(ptr_bias),
+                        &oscales[bgmmc.is_oscale_per_n * n],
+                        post_ops_binary_rhs_arg_vec.data(),
+                        static_cast<size_t>(n)};
+
                 brgemm_kernel_execute_postops(brg_kernel, gemm_batch,
-                        addr_batch, (void *)ptr_C, (void *)ptr_D,
-                        (void *)ptr_bias, &oscales[bgmmc.is_oscale_per_n * n],
-                        is_amx ? (void *)wsp_tile
-                               : (bgmmc.signed_input
-                                               ? (void *)&compensation[comp_idx]
-                                               : nullptr));
+                        addr_batch, (void *)ptr_C, (void *)ptr_D, post_ops_data,
+                        scratch);
             } else {
                 brgemm_kernel_execute(brg_kernel, gemm_batch, addr_batch,
                         (void *)ptr_C, is_amx ? (void *)wsp_tile : nullptr);
@@ -322,13 +335,20 @@ void brgemm_matmul_t<isa>::execute_body(const exec_ctx_t &ctx) const {
             if (is_tile_reconf_required)
                 amx_tile_configure(&brg_kernel_palettes_[brg_ker_idx][0]);
             if (are_post_ops_applicable && k_blk_idx == K_chunks - 1) {
-                brgemm_kernel_execute_postops(brg_kernel_k_tail, 1, addr_batch,
-                        (void *)ptr_C, (void *)ptr_D, (void *)ptr_bias,
+                void *scratch = is_amx
+                        ? static_cast<void *>(wsp_tile)
+                        : (bgmmc.signed_input ? static_cast<void *>(
+                                   const_cast<int *>(&compensation[comp_idx]))
+                                              : nullptr);
+
+                const brgemm_post_ops_data_t post_ops_data {
+                        static_cast<const void *>(ptr_bias),
                         &oscales[bgmmc.is_oscale_per_n * n],
-                        is_amx ? (void *)wsp_tile
-                               : (bgmmc.signed_input
-                                               ? (void *)&compensation[comp_idx]
-                                               : nullptr));
+                        post_ops_binary_rhs_arg_vec.data(),
+                        static_cast<size_t>(n)};
+
+                brgemm_kernel_execute_postops(brg_kernel_k_tail, 1, addr_batch,
+                        (void *)ptr_C, (void *)ptr_D, post_ops_data, scratch);
             } else {
                 brgemm_kernel_execute(brg_kernel_k_tail, 1, addr_batch,
                         (void *)ptr_C, is_amx ? (void *)wsp_tile : nullptr);
-- 
2.25.1

