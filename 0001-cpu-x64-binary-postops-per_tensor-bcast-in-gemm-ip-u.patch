From 1e89e1e9dd27dbdab249ba556e3403b5b9fc247b Mon Sep 17 00:00:00 2001
From: Dariusz Sciebura <dariusz.sciebura@intel.com>
Date: Fri, 5 Mar 2021 04:51:01 -0800
Subject: [PATCH] cpu: x64: binary postops per_tensor bcast in gemm ip utils

---
 src/cpu/binary_injector_utils.cpp             |  22 ++-
 src/cpu/binary_injector_utils.hpp             |  43 ++++-
 src/cpu/gemm_inner_product.cpp                |   4 +-
 src/cpu/gemm_inner_product_utils.cpp          |   9 +-
 src/cpu/gemm_inner_product_utils.hpp          |   8 +-
 src/cpu/gemm_x8s8s32x_inner_product.cpp       |   6 +-
 src/cpu/matmul/gemm_bf16_matmul.cpp           |   9 +-
 src/cpu/matmul/gemm_f32_matmul.cpp            |   9 +-
 src/cpu/matmul/gemm_x8s8s32x_matmul.cpp       |   6 +-
 src/cpu/x64/gemm_bf16_inner_product.cpp       |   4 +-
 .../x64/injectors/jit_uni_binary_injector.cpp |  29 ++-
 src/cpu/x64/jit_gemm_inner_product_utils.cpp  | 172 ++++++++++++++----
 .../inputs/matmul/harness_matmul_runtime_f32  |   2 +-
 .../inputs/matmul/harness_matmul_runtime_int8 |   3 +-
 tests/benchdnn/inputs/matmul/test_matmul_all  |   2 +-
 15 files changed, 254 insertions(+), 74 deletions(-)

diff --git a/src/cpu/binary_injector_utils.cpp b/src/cpu/binary_injector_utils.cpp
index 193aeda40..41b267bea 100644
--- a/src/cpu/binary_injector_utils.cpp
+++ b/src/cpu/binary_injector_utils.cpp
@@ -1,5 +1,5 @@
 /*******************************************************************************
-* Copyright 2020 Intel Corporation
+* Copyright 2020-2021 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
@@ -42,6 +42,26 @@ std::vector<const void *> prepare_binary_args(const post_ops_t &post_ops,
     return post_ops_binary_rhs_arg_vec;
 }
 
+bool bcast_strategy_present(
+        const std::vector<broadcasting_strategy_t> &post_ops_bcasts,
+        const broadcasting_strategy_t bcast_strategy) {
+    for (const auto &post_op_bcast : post_ops_bcasts)
+        if (post_op_bcast == bcast_strategy) return true;
+    return false;
+}
+
+std::vector<broadcasting_strategy_t> extract_bcast_strategies(
+        const std::vector<dnnl_post_ops::entry_t> &post_ops,
+        const memory_desc_wrapper &dst_md) {
+    std::vector<broadcasting_strategy_t> post_ops_bcasts;
+    post_ops_bcasts.reserve(post_ops.size());
+    for (const auto &post_op : post_ops)
+        if (post_op.is_binary())
+            post_ops_bcasts.emplace_back(get_rhs_arg_broadcasting_strategy(
+                    post_op.binary.src1_desc, dst_md));
+    return post_ops_bcasts;
+}
+
 } // namespace binary_injector_utils
 } // namespace cpu
 } // namespace impl
diff --git a/src/cpu/binary_injector_utils.hpp b/src/cpu/binary_injector_utils.hpp
index 6310902b6..32665682f 100644
--- a/src/cpu/binary_injector_utils.hpp
+++ b/src/cpu/binary_injector_utils.hpp
@@ -1,5 +1,5 @@
 /*******************************************************************************
-* Copyright 2020 Intel Corporation
+* Copyright 2020-2021 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
@@ -17,9 +17,12 @@
 #ifndef CPU_BINARY_INJECTOR_UTILS_HPP
 #define CPU_BINARY_INJECTOR_UTILS_HPP
 
+#include <tuple>
 #include <vector>
 
+#include "common/broadcast_strategy.hpp"
 #include "common/c_types_map.hpp"
+#include "common/primitive_attr.hpp"
 #include "common/primitive_exec_types.hpp"
 
 namespace dnnl {
@@ -38,6 +41,44 @@ std::vector<const void *> prepare_binary_args(const post_ops_t &post_ops,
         const dnnl::impl::exec_ctx_t &ctx,
         const unsigned first_arg_idx_offset = 0);
 
+bool bcast_strategy_present(
+        const std::vector<broadcasting_strategy_t> &post_ops_bcasts,
+        const broadcasting_strategy_t bcast_strategy);
+
+std::vector<broadcasting_strategy_t> extract_bcast_strategies(
+        const std::vector<dnnl_post_ops::entry_t> &post_ops,
+        const memory_desc_wrapper &dst_md);
+
+/* 
+ * Returns a map of bcast_strategies to bools indicating existence of
+ * binary postop with a particular bcast strategy in post_ops vector.
+ */
+template <typename... Str>
+std::map<broadcasting_strategy_t, bool> bcast_strategies_present_map(
+        const std::vector<dnnl_post_ops::entry_t> &post_ops,
+        const memory_desc_wrapper &dst_md, Str... bcast_strategies) {
+    const auto post_ops_bcasts = extract_bcast_strategies(post_ops, dst_md);
+
+    return std::map<broadcasting_strategy_t, bool> {std::make_pair(
+            bcast_strategies,
+            bcast_strategy_present(post_ops_bcasts, bcast_strategies))...};
+}
+
+/* 
+ * Returns a tuple of bools, which size is equal to number of bcast
+ * strategies passed in. Values at consecutive positions indicate existence of
+ * binary postop with a particular bcast strategy in post_ops vector.
+ */
+template <typename... Str>
+auto bcast_strategies_present_tup(
+        const std::vector<dnnl_post_ops::entry_t> &post_ops,
+        const memory_desc_wrapper &dst_md, Str... bcast_strategies)
+        -> decltype(std::make_tuple((bcast_strategies, false)...)) {
+    const auto post_ops_bcasts = extract_bcast_strategies(post_ops, dst_md);
+    return std::make_tuple(
+            bcast_strategy_present(post_ops_bcasts, bcast_strategies)...);
+}
+
 } // namespace binary_injector_utils
 } // namespace cpu
 } // namespace impl
diff --git a/src/cpu/gemm_inner_product.cpp b/src/cpu/gemm_inner_product.cpp
index 7b1dbafec..31cf4332b 100644
--- a/src/cpu/gemm_inner_product.cpp
+++ b/src/cpu/gemm_inner_product.cpp
@@ -1,5 +1,5 @@
 /*******************************************************************************
-* Copyright 2016-2020 Intel Corporation
+* Copyright 2016-2021 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
@@ -63,7 +63,7 @@ status_t gemm_inner_product_fwd_t<data_type>::execute_forward(
         parallel(force_sequential ? 1 : 0, [&](int ithr, int nthr) {
             size_t start, end;
             balance211((size_t)(OC * MB), nthr, ithr, start, end);
-            (*pp_kernel_)(dst, dst, (char *)bias, scales, start, end, 0,
+            (*pp_kernel_)(dst, dst, (char *)bias, scales, start, start, end, 0,
                     pd()->OC() * pd()->OD() * pd()->OH() * pd()->OW(), nullptr,
                     post_ops_binary_rhs_arg_vec.data(), dst, ctx,
                     *pd()->dst_md());
diff --git a/src/cpu/gemm_inner_product_utils.cpp b/src/cpu/gemm_inner_product_utils.cpp
index f30d21596..067cf1e84 100644
--- a/src/cpu/gemm_inner_product_utils.cpp
+++ b/src/cpu/gemm_inner_product_utils.cpp
@@ -47,8 +47,9 @@ struct ref_pp_kernel_t : public pp_kernel_t<acc_type, dst_type> {
     using dst_data_t = typename prec_traits<dst_type>::type;
 
     void operator()(dst_data_t *dst, const acc_data_t *acc, const char *bias,
-            const float *scales, size_t start, size_t end, size_t runtime_oc,
-            dim_t dst_mb_stride, const float *dst_zero_points,
+            const float *scales, size_t start, size_t dst_logical_offset,
+            size_t end, size_t runtime_oc, dim_t dst_mb_stride,
+            const float *dst_zero_points,
             const void *post_ops_binary_rhs_arg_vec, const void *dst_orig,
             const exec_ctx_t &ctx, const memory_desc_t &dst_md) const override;
 
@@ -59,8 +60,8 @@ private:
 template <data_type_t acc_type, data_type_t dst_type>
 void ref_pp_kernel_t<acc_type, dst_type>::operator()(dst_data_t *dst,
         const acc_data_t *acc, const char *bias, const float *scales,
-        size_t start, size_t end, size_t runtime_oc, dim_t dst_mb_stride,
-        const float *dst_zero_points,
+        size_t start, size_t dst_logical_offset, size_t end, size_t runtime_oc,
+        dim_t dst_mb_stride, const float *dst_zero_points,
         const void * /* post_ops_binary_rhs_arg_vec */,
         const void * /* dst_orig */, const exec_ctx_t &ctx,
         const memory_desc_t &dst_md) const {
diff --git a/src/cpu/gemm_inner_product_utils.hpp b/src/cpu/gemm_inner_product_utils.hpp
index ba1753860..d69998a99 100644
--- a/src/cpu/gemm_inner_product_utils.hpp
+++ b/src/cpu/gemm_inner_product_utils.hpp
@@ -1,5 +1,5 @@
 /*******************************************************************************
-* Copyright 2019-2020 Intel Corporation
+* Copyright 2019-2021 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
@@ -49,9 +49,9 @@ struct pp_kernel_t {
     bool sequential_kernel() const { return mb_blk_kernel_; }
 
     virtual void operator()(dst_data_t *dst, const acc_data_t *acc,
-            const char *bias, const float *scales, size_t start, size_t end,
-            size_t runtime_oc, dim_t dst_mb_stride,
-            const float *dst_zero_points,
+            const char *bias, const float *scales, size_t start,
+            size_t dst_logical_offset, size_t end, size_t runtime_oc,
+            dim_t dst_mb_stride, const float *dst_zero_points,
             const void *post_ops_binary_rhs_arg_vec, const void *dst_orig,
             const exec_ctx_t &ctx, const memory_desc_t &dst_md) const = 0;
 
diff --git a/src/cpu/gemm_x8s8s32x_inner_product.cpp b/src/cpu/gemm_x8s8s32x_inner_product.cpp
index b16c22ac5..d0320167e 100644
--- a/src/cpu/gemm_x8s8s32x_inner_product.cpp
+++ b/src/cpu/gemm_x8s8s32x_inner_product.cpp
@@ -1,5 +1,5 @@
 /*******************************************************************************
-* Copyright 2018-2020 Intel Corporation
+* Copyright 2018-2021 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
@@ -74,8 +74,8 @@ status_t gemm_x8s8s32x_inner_product_fwd_t<src_type, dst_type>::execute_forward(
         parallel(force_sequential ? 1 : 0, [&](int ithr, int nthr) {
             size_t start, end;
             balance211((size_t)(OC * MB), nthr, ithr, start, end);
-            (*pp_kernel_)(dst, acc, bias, scales, start, end, 0, 0, nullptr,
-                    post_ops_binary_rhs_arg_vec.data(), dst, ctx,
+            (*pp_kernel_)(dst, acc, bias, scales, start, start, end, 0, 0,
+                    nullptr, post_ops_binary_rhs_arg_vec.data(), dst, ctx,
                     *pd()->dst_md());
         });
     }
diff --git a/src/cpu/matmul/gemm_bf16_matmul.cpp b/src/cpu/matmul/gemm_bf16_matmul.cpp
index 270a04487..f7871ea6a 100644
--- a/src/cpu/matmul/gemm_bf16_matmul.cpp
+++ b/src/cpu/matmul/gemm_bf16_matmul.cpp
@@ -262,7 +262,7 @@ status_t gemm_bf16_matmul_t<dst_type>::execute_ref(
                             bias
                                     + static_cast<ptrdiff_t>(i_work % N)
                                             * bia_dt_size,
-                            pp_scales, 0, gemm_M * gemm_N,
+                            pp_scales, 0, i_work, gemm_M * gemm_N,
                             static_cast<size_t>(gemm_N), ldc, nullptr,
                             post_ops_binary_rhs_arg_vec.data(), dst, ctx,
                             *pd()->dst_md());
@@ -285,9 +285,10 @@ status_t gemm_bf16_matmul_t<dst_type>::execute_ref(
             parallel(force_sequential ? 1 : 0, [&](int ithr, int nthr) {
                 size_t start {}, end {};
                 balance211((size_t)(M * N), nthr, ithr, start, end);
-                (*pp_kernel_)(dst, acc, bias, pp_scales, start, end, (size_t)N,
-                        ldc, nullptr, post_ops_binary_rhs_arg_vec.data(), dst,
-                        ctx, *pd()->dst_md());
+                (*pp_kernel_)(dst, acc, bias, pp_scales, start, start, end,
+                        (size_t)N, ldc, nullptr,
+                        post_ops_binary_rhs_arg_vec.data(), dst, ctx,
+                        *pd()->dst_md());
             });
         }
     }
diff --git a/src/cpu/matmul/gemm_f32_matmul.cpp b/src/cpu/matmul/gemm_f32_matmul.cpp
index 9b27b59ea..42d85bcd2 100644
--- a/src/cpu/matmul/gemm_f32_matmul.cpp
+++ b/src/cpu/matmul/gemm_f32_matmul.cpp
@@ -225,7 +225,7 @@ status_t gemm_f32_matmul_t::execute_ref(const exec_ctx_t &ctx) const {
                             bias
                                     + static_cast<ptrdiff_t>(i_work % N)
                                             * bia_dt_size,
-                            pp_scales, 0, gemm_M * gemm_N,
+                            pp_scales, 0, i_work, gemm_M * gemm_N,
                             static_cast<size_t>(gemm_N), ldc, nullptr,
                             post_ops_binary_rhs_arg_vec.data(), dst, ctx,
                             *pd()->dst_md());
@@ -247,9 +247,10 @@ status_t gemm_f32_matmul_t::execute_ref(const exec_ctx_t &ctx) const {
             parallel(force_sequential ? 1 : 0, [&](int ithr, int nthr) {
                 size_t start {}, end {};
                 balance211((size_t)(M * N), nthr, ithr, start, end);
-                (*pp_kernel_)(dst, dst, bias, pp_scales, start, end, (size_t)N,
-                        ldc, nullptr, post_ops_binary_rhs_arg_vec.data(), dst,
-                        ctx, *pd()->dst_md());
+                (*pp_kernel_)(dst, dst, bias, pp_scales, start, start, end,
+                        (size_t)N, ldc, nullptr,
+                        post_ops_binary_rhs_arg_vec.data(), dst, ctx,
+                        *pd()->dst_md());
             });
         }
     }
diff --git a/src/cpu/matmul/gemm_x8s8s32x_matmul.cpp b/src/cpu/matmul/gemm_x8s8s32x_matmul.cpp
index 96fa530d9..967ab7322 100644
--- a/src/cpu/matmul/gemm_x8s8s32x_matmul.cpp
+++ b/src/cpu/matmul/gemm_x8s8s32x_matmul.cpp
@@ -323,7 +323,7 @@ status_t gemm_x8s8s32x_matmul_t<src_type, weights_type, dst_type>::execute_ref(
                             bias
                                     + static_cast<ptrdiff_t>(i_work % N)
                                             * bia_dt_size,
-                            scales, 0, gemm_M * gemm_N,
+                            scales, 0, i_work, gemm_M * gemm_N,
                             static_cast<size_t>(gemm_N), ldc,
                             &dst_zero_point_f32,
                             post_ops_binary_rhs_arg_vec.data(), dst, ctx,
@@ -365,8 +365,8 @@ status_t gemm_x8s8s32x_matmul_t<src_type, weights_type, dst_type>::execute_ref(
             parallel(force_sequential ? 1 : 0, [&](int ithr, int nthr) {
                 size_t start {}, end {};
                 balance211((size_t)(M * N), nthr, ithr, start, end);
-                (*pp_kernel_)(dst, acc, bias, scales, start, end, (size_t)N,
-                        ldc, &dst_zero_point_f32,
+                (*pp_kernel_)(dst, acc, bias, scales, start, start, end,
+                        (size_t)N, ldc, &dst_zero_point_f32,
                         post_ops_binary_rhs_arg_vec.data(), dst, ctx,
                         *pd()->dst_md());
             });
diff --git a/src/cpu/x64/gemm_bf16_inner_product.cpp b/src/cpu/x64/gemm_bf16_inner_product.cpp
index 96bb26fce..94782f2ec 100644
--- a/src/cpu/x64/gemm_bf16_inner_product.cpp
+++ b/src/cpu/x64/gemm_bf16_inner_product.cpp
@@ -74,8 +74,8 @@ status_t gemm_bf16_inner_product_fwd_t<dst_data_type>::execute_forward(
             size_t start = 0, end = 0;
             size_t work_size = M * N;
             balance211(work_size, nthr, ithr, start, end);
-            (*pp_kernel_)(dst, acc, bias, scales, start, end, 0, 0, nullptr,
-                    post_ops_binary_rhs_arg_vec.data(), dst, ctx,
+            (*pp_kernel_)(dst, acc, bias, scales, start, start, end, 0, 0,
+                    nullptr, post_ops_binary_rhs_arg_vec.data(), dst, ctx,
                     *pd()->dst_md());
         });
     }
diff --git a/src/cpu/x64/injectors/jit_uni_binary_injector.cpp b/src/cpu/x64/injectors/jit_uni_binary_injector.cpp
index 3693d104f..96bc6ba86 100644
--- a/src/cpu/x64/injectors/jit_uni_binary_injector.cpp
+++ b/src/cpu/x64/injectors/jit_uni_binary_injector.cpp
@@ -19,6 +19,7 @@
 #include "common/primitive.hpp"
 #include "common/primitive_attr.hpp"
 #include "common/primitive_exec_types.hpp"
+#include "common/utils.hpp"
 #include "cpu/x64/injectors/jit_uni_binary_injector.hpp"
 
 namespace dnnl {
@@ -32,11 +33,35 @@ bool is_data_supported(cpu_isa_t isa, data_type_t data_type) {
             utils::one_of(isa, avx512_core_bf16, avx512_core));
 }
 
+static bool src1_desc_layout_same_as_dst_d(
+        const dnnl::impl::memory_desc_t &src1_desc,
+        const memory_desc_wrapper &dst_d) {
+    if (dst_d.md_ == nullptr) return false;
+    const auto &lhs = src1_desc;
+    const auto &rhs = *(dst_d.md_);
+
+    using namespace dnnl::impl::utils;
+    return lhs.ndims == rhs.ndims
+            && (lhs.format_kind == rhs.format_kind
+                    || one_of(
+                            format_kind::any, lhs.format_kind, rhs.format_kind))
+            && array_cmp(lhs.dims, rhs.dims, lhs.ndims)
+            && array_cmp(lhs.padded_dims, rhs.padded_dims, lhs.ndims)
+            && array_cmp(lhs.padded_offsets, rhs.padded_offsets, lhs.ndims)
+            && lhs.offset0 == rhs.offset0;
+}
+
 bool is_bcast_supported(const dnnl::impl::memory_desc_t &src1_desc,
         const memory_desc_wrapper &dst_d,
         const bcast_set_t &supported_strategy_set) {
     const auto bcast_type = get_rhs_arg_broadcasting_strategy(
             src1_desc, dst_d, supported_strategy_set);
+
+    if (bcast_type == broadcasting_strategy_t::no_broadcast) {
+        // in case of no broadcast data layout of dst and src1 have to be the same
+        if (!src1_desc_layout_same_as_dst_d(src1_desc, dst_d)) return false;
+    }
+
     return bcast_type != broadcasting_strategy_t::unsupported;
 }
 
@@ -686,7 +711,7 @@ void jit_uni_binary_injector_t<isa>::execute_broadcast_tail(
             && "Opmask is not set for tail loading avx512");
     const auto &tail_opmask = rhs_arg_static_params_.tail_opmask;
 
-    host_->uni_vxorps(tmp_vmm, tmp_vmm, tmp_vmm);
+    // host_->uni_vxorps(tmp_vmm, tmp_vmm, tmp_vmm);
     switch (data_type) {
         case data_type::f32:
             host_->vbroadcastss(tmp_vmm | tail_opmask | host_->T_z, rhs_addr);
@@ -912,7 +937,7 @@ void jit_uni_binary_injector_t<isa>::load_rhs_tail(
             && "Opmask is not set for tail loading avx512");
 
     const auto &tail_opmask = rhs_arg_static_params_.tail_opmask;
-    host_->uni_vxorps(tmp_vmm, tmp_vmm, tmp_vmm);
+    // host_->uni_vxorps(tmp_vmm, tmp_vmm, tmp_vmm);
 
     switch (data_type) {
         case data_type::f32:
diff --git a/src/cpu/x64/jit_gemm_inner_product_utils.cpp b/src/cpu/x64/jit_gemm_inner_product_utils.cpp
index 39d079851..6b220f16f 100644
--- a/src/cpu/x64/jit_gemm_inner_product_utils.cpp
+++ b/src/cpu/x64/jit_gemm_inner_product_utils.cpp
@@ -48,21 +48,33 @@ struct jit_pp_kernel_t : public pp_kernel_t<acc_type, dst_type>,
     using dst_data_t = typename prec_traits<dst_type>::type;
 
     void operator()(dst_data_t *dst, const acc_data_t *acc, const char *bias,
-            const float *scales, size_t start, size_t end, size_t runtime_oc,
-            dim_t dst_mb_stride, const float *dst_zero_points,
+            const float *scales, size_t start, size_t dst_logical_offset,
+            size_t end, size_t runtime_oc, dim_t dst_mb_stride,
+            const float *dst_zero_points,
             const void *post_ops_binary_rhs_arg_vec, const void *dst_orig,
             const exec_ctx_t &ctx, const memory_desc_t &dst_md) const override;
 
     status_t create_kernel() override { return jit_generator::create_kernel(); }
 
 private:
-    void apply_postops(const bool apply_mask, const int vmm_idx);
+    void apply_postops(
+            const bool apply_mask, const int vmm_idx, const size_t offset);
     void generate() override;
     void compute_oc_channel_blk();
     void compute_mb_blk(); // vectorize across minibatch
+
+    void advance_binary_postops_off(
+            const size_t per_oc_offset, const size_t per_tensor_offset);
+
+    void advance_binary_postops_off(const Xbyak::Reg64 per_oc_offset,
+            const Xbyak::Reg64 per_tensor_offset);
+
+    template <typename T>
+    void advance_binary_postops_per_oc_off(const T &offset);
+
     template <typename T>
-    void advance_binary_postops_off(const T &offset);
-    void zero_binary_postops_off();
+    void advance_binary_postops_per_tensor_off(const T &offset);
+    void zero_binary_postops_off(const Xbyak::Reg64 &reg);
 
     struct ker_args_t {
         dst_data_t *dst = nullptr;
@@ -74,6 +86,7 @@ private:
         size_t oc = 0;
         size_t len = 0;
         size_t oc_offset = 0;
+        size_t dst_logical_offset = 0;
         dim_t dst_mb_stride = 0;
         const void *post_ops_binary_rhs_arg_vec = nullptr;
         const void *dst_orig = nullptr;
@@ -92,6 +105,7 @@ private:
     const Xbyak::Reg64 reg_binary_inj_param_ = abi_param1;
 #endif
 
+    Xbyak::Reg64 reg_stack_frame_ = rbp;
     Xbyak::Reg64 reg_param = abi_param1;
     Xbyak::Reg64 reg_dst = rdx;
     Xbyak::Reg64 reg_acc = rax;
@@ -134,9 +148,14 @@ private:
     int compute_vreg_prev_dst_shift_ = 0;
 
     const size_t vlen = cpu_isa_traits<avx512_core>::vlen / sizeof(float);
-    constexpr static int reg64_size = sizeof(int64_t);
-    constexpr static int reg_binary_post_op_oc_off = 0;
-    constexpr static int stack_space_needed = 1 * reg64_size;
+    static constexpr int reg64_size_ = sizeof(int64_t);
+    static constexpr int reg_binary_post_op_oc_off_ = 0;
+    static constexpr int reg_binary_post_op_offset_ = 1 * reg64_size_;
+
+    static constexpr int stack_space_needed_ = 2 * reg64_size_;
+
+    bool any_binary_postop_is_no_bcast_type_ = false;
+    bool any_binary_postop_is_per_oc_bcast_type_ = false;
 
     int vreg_dst_idx(const int iter) const {
         int idx = idx_compute_vreg_start_ + iter * compute_vregs_per_iter_;
@@ -204,18 +223,24 @@ jit_pp_kernel_t<acc_type, dst_type>::jit_pp_kernel_t(size_t OC, size_t MB,
     if (this->do_eltwise_ || this->do_binary_) {
 #define PARAM_OFF(field) offsetof(ker_args_t, field)
         static constexpr bool preserve_gpr = true;
-        static constexpr bool preserve_vmm = true;
+        static constexpr bool preserve_vmm = false;
         static constexpr size_t helper_vmm_idx = 31;
         static constexpr size_t tail_size = 1;
         static constexpr bool use_exact_tail_scalar_bcast = false;
+        const auto dst_md_wrapper = memory_desc_wrapper(*dst_md);
         const binary_injector::rhs_arg_static_params_t rhs_arg_static_params {
                 helper_vmm_idx, eltwise_reserved_gpr_, r14, preserve_gpr,
                 preserve_vmm, PARAM_OFF(post_ops_binary_rhs_arg_vec),
-                memory_desc_wrapper(*dst_md), tail_size, kreg_rem_mask,
+                dst_md_wrapper, tail_size, kreg_rem_mask,
                 use_exact_tail_scalar_bcast};
 
+        const bcast_set_t supported_bcast_strategies
+                = {broadcasting_strategy_t::scalar,
+                        broadcasting_strategy_t::per_oc,
+                        broadcasting_strategy_t::no_broadcast};
         const binary_injector::static_params_t binary_static_params {
-                reg_binary_inj_param_, rhs_arg_static_params};
+                reg_binary_inj_param_, supported_bcast_strategies,
+                rhs_arg_static_params};
         static constexpr bool save_state = true;
         const eltwise_injector::static_params_t eltwise_static_params {
                 save_state, reg_tmp_comp, eltwise_reserved_opmask_};
@@ -223,18 +248,27 @@ jit_pp_kernel_t<acc_type, dst_type>::jit_pp_kernel_t(size_t OC, size_t MB,
         postops_injector_ = utils::make_unique<
                 injector::jit_uni_postops_injector_t<avx512_core>>(this,
                 this->post_ops_, binary_static_params, eltwise_static_params);
+
+        using namespace dnnl::impl::cpu::binary_injector_utils;
+        std::tie(any_binary_postop_is_no_bcast_type_,
+                any_binary_postop_is_per_oc_bcast_type_)
+                = bcast_strategies_present_tup(this->post_ops_.entry_,
+                        dst_md_wrapper, broadcasting_strategy_t::no_broadcast,
+                        broadcasting_strategy_t::per_oc);
     }
 #undef PARAM_OFF
 }
 
 template <data_type_t acc_type, data_type_t dst_type>
 template <typename T>
-void jit_pp_kernel_t<acc_type, dst_type>::advance_binary_postops_off(
+void jit_pp_kernel_t<acc_type, dst_type>::advance_binary_postops_per_oc_off(
         const T &offset) {
+
     const auto binary_post_op_oc_off_reg = reg_tmp_comp;
-    const auto binary_post_op_oc_off_on_stack
-            = ptr[rsp + reg_binary_post_op_oc_off];
-    mov(binary_post_op_oc_off_reg, binary_post_op_oc_off_on_stack);
+    const auto binary_post_op_current_offset_on_stack
+            = ptr[rsp + reg_binary_post_op_oc_off_];
+
+    mov(binary_post_op_oc_off_reg, binary_post_op_current_offset_on_stack);
     add(binary_post_op_oc_off_reg, offset);
 
     Xbyak::Label end;
@@ -243,35 +277,80 @@ void jit_pp_kernel_t<acc_type, dst_type>::advance_binary_postops_off(
     xor_(binary_post_op_oc_off_reg, binary_post_op_oc_off_reg);
     L(end);
 
-    mov(binary_post_op_oc_off_on_stack, binary_post_op_oc_off_reg);
+    mov(binary_post_op_current_offset_on_stack, binary_post_op_oc_off_reg);
+}
+
+template <data_type_t acc_type, data_type_t dst_type>
+template <typename T>
+void jit_pp_kernel_t<acc_type, dst_type>::advance_binary_postops_per_tensor_off(
+        const T &offset) {
+
+    const auto binary_post_op_offset_reg = reg_tmp_comp;
+    const auto binary_post_op_current_offset_on_stack
+            = ptr[rsp + reg_binary_post_op_offset_];
+    mov(binary_post_op_offset_reg, binary_post_op_current_offset_on_stack);
+    add(binary_post_op_offset_reg, offset);
+    mov(binary_post_op_current_offset_on_stack, binary_post_op_offset_reg);
+}
+
+/*
+ * Advance binary postops offsets with per_tensor_offset passed as plain value
+ * type (const offset value).
+ */
+template <data_type_t acc_type, data_type_t dst_type>
+void jit_pp_kernel_t<acc_type, dst_type>::advance_binary_postops_off(
+        const size_t per_oc_offset, const size_t per_tensor_offset) {
+    if (any_binary_postop_is_per_oc_bcast_type_ && per_oc_offset)
+        advance_binary_postops_per_oc_off(per_oc_offset);
+    if (any_binary_postop_is_no_bcast_type_ && per_tensor_offset)
+        advance_binary_postops_per_tensor_off(per_tensor_offset);
 }
 
+/*
+ * Advance binary postops offsets with per_tensor_offset passed in Reg64.
+ */
 template <data_type_t acc_type, data_type_t dst_type>
-void jit_pp_kernel_t<acc_type, dst_type>::zero_binary_postops_off() {
-    mov(EVEX_compress_addr(rsp, reg_binary_post_op_oc_off), 0);
+void jit_pp_kernel_t<acc_type, dst_type>::advance_binary_postops_off(
+        const Xbyak::Reg64 per_oc_offset,
+        const Xbyak::Reg64 per_tensor_offset) {
+    if (any_binary_postop_is_per_oc_bcast_type_)
+        advance_binary_postops_per_oc_off(per_oc_offset);
+    if (any_binary_postop_is_no_bcast_type_)
+        advance_binary_postops_per_tensor_off(per_tensor_offset);
+}
+
+template <data_type_t acc_type, data_type_t dst_type>
+void jit_pp_kernel_t<acc_type, dst_type>::zero_binary_postops_off(
+        const Xbyak::Reg64 &reg) {
+    mov(EVEX_compress_addr(rsp, reg_binary_post_op_oc_off_), 0);
 }
 
 template <data_type_t acc_type, data_type_t dst_type>
 void jit_pp_kernel_t<acc_type, dst_type>::apply_postops(
-        const bool apply_mask, const int vmm_idx) {
-#define PARAM_OFF(x) offsetof(ker_args_t, x)
+        const bool apply_mask, const int vmm_idx, const size_t offset) {
     if (this->do_eltwise_ || this->do_binary_) {
         if (this->do_binary_) {
             binary_injector::rhs_arg_dynamic_params_t rhs_arg_params;
-            const auto oc_off_oprnd = reg_tmp_comp;
-            rhs_arg_params.vmm_idx_to_oc_off_oprnd.emplace(
-                    vmm_idx, oc_off_oprnd);
-            rhs_arg_params.vmm_idx_to_out_off_oprnd.emplace(
-                    vmm_idx, oc_off_oprnd);
-            if (apply_mask) rhs_arg_params.vmm_tail_idx_.emplace(vmm_idx);
+            if (any_binary_postop_is_per_oc_bcast_type_) {
+                const auto oc_off_oprnd = reg_tmp_comp;
+                mov(oc_off_oprnd, ptr[rsp + reg_binary_post_op_oc_off_]);
+                rhs_arg_params.vmm_idx_to_oc_off_oprnd.emplace(
+                        vmm_idx, oc_off_oprnd);
+            }
 
-            mov(oc_off_oprnd, ptr[rsp + reg_binary_post_op_oc_off]);
+            if (apply_mask) rhs_arg_params.vmm_tail_idx_.emplace(vmm_idx);
 
+            if (any_binary_postop_is_no_bcast_type_) {
+                rhs_arg_params.vmm_idx_to_out_elem_off_val.emplace(
+                        vmm_idx, static_cast<int>(offset));
+                rhs_arg_params.vmm_idx_to_out_elem_off_addr.emplace(vmm_idx,
+                        ptr[reg_stack_frame_ - stack_space_needed_
+                                + reg_binary_post_op_offset_]);
+            }
             postops_injector_->compute_vector(vmm_idx, rhs_arg_params);
         } else
             postops_injector_->compute_vector(vmm_idx);
     }
-#undef PARAM_OFF
 }
 
 template <data_type_t acc_type, data_type_t dst_type>
@@ -291,7 +370,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::compute_oc_channel_blk() {
         }
 
         if (this->do_binary_) {
-            if (offset) advance_binary_postops_off(vlen);
+            advance_binary_postops_off(offset, 0);
             if (apply_mask) kmovq(opmask_binary, kreg_rem_mask);
         }
 
@@ -361,7 +440,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::compute_oc_channel_blk() {
             vfmadd231ps(vreg_dst_, vreg_prev_dst_, vreg_sum_scale);
         }
 
-        apply_postops(apply_mask, dst_idx);
+        apply_postops(apply_mask, dst_idx, offset);
 
         if (this->do_dst_zero_points_)
             vaddps(vreg_dst_, vreg_dst_, vreg_dst_zero_points);
@@ -399,7 +478,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::compute_oc_channel_blk() {
         if (this->do_scale_ && this->scale_idx_mult_ == 1)
             add(reg_scales, offset * sizeof(float));
         if (this->do_bias()) add(reg_bias, offset * this->bias_data_type_size_);
-        if (this->do_binary_) advance_binary_postops_off(vlen);
+        if (this->do_binary_) advance_binary_postops_off(vlen, offset);
     };
 
     // Advance all pointers by a value stored in a register
@@ -410,7 +489,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::compute_oc_channel_blk() {
             lea(reg_scales, ptr[reg_scales + offset * sizeof(float)]);
         if (this->do_bias())
             lea(reg_bias, ptr[reg_bias + offset * this->bias_data_type_size_]);
-        if (this->do_binary_) advance_binary_postops_off(offset);
+        if (this->do_binary_) advance_binary_postops_off(offset, offset);
     };
 
     // incase of non-trivial dst_mb_strides, fixup the reg_dst and reg_acc
@@ -429,7 +508,8 @@ void jit_pp_kernel_t<acc_type, dst_type>::compute_oc_channel_blk() {
             lea(reg_bias, ptr[reg_bias + reg_oc * this->bias_data_type_size_]);
         if (this->do_scale_ && this->scale_idx_mult_ == 1)
             lea(reg_scales, ptr[reg_scales + reg_oc * sizeof(float)]);
-        if (this->do_binary_) zero_binary_postops_off();
+        if (this->do_binary_) zero_binary_postops_off(reg_oc);
+
         neg(reg_oc);
     };
 
@@ -443,6 +523,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::compute_oc_channel_blk() {
         {
             compute(0, 0, false);
             advance_ptrs_imm(vlen);
+
             sub(reg_tmp, vlen);
             cmp(reg_tmp, vlen);
             jge(l_loop, T_NEAR);
@@ -538,6 +619,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::compute_oc_channel_blk() {
                     for (size_t offset = 0; offset < OC_loop; offset += vlen)
                         compute(offset, offset / vlen, false);
                     advance_ptrs_imm(OC_loop);
+
                     sub(reg_tmp, OC_loop);
                     jnz(l_oc_loop);
                 }
@@ -735,9 +817,17 @@ void jit_pp_kernel_t<acc_type, dst_type>::generate() {
     mov(reg_len, ptr[reg_param + PARAM_OFF(len)]);
     mov(reg_oc_offset, ptr[reg_param + PARAM_OFF(oc_offset)]);
     if (this->do_binary_) {
-        // zero initialize binary post_ops offset accumulator (store on stack)
-        sub(rsp, stack_space_needed);
-        mov(ptr[rsp + reg_binary_post_op_oc_off], reg_oc_offset);
+        mov(reg_stack_frame_, rsp);
+        sub(rsp, stack_space_needed_);
+        if (any_binary_postop_is_per_oc_bcast_type_) {
+            // zero initialize binary post_ops oc offset accumulator
+            mov(ptr[rsp + reg_binary_post_op_oc_off_], reg_oc_offset);
+        }
+        if (any_binary_postop_is_no_bcast_type_) {
+            // initialize binary post_ops no bcast offset accumulator
+            mov(reg_tmp_comp, ptr[reg_param + PARAM_OFF(dst_logical_offset)]);
+            mov(ptr[rsp + reg_binary_post_op_offset_], reg_tmp_comp);
+        }
     }
     if (this->do_scale_ && this->scale_idx_mult_ == 0)
         vbroadcastss(vreg_scale, dword[reg_scales]);
@@ -776,7 +866,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::generate() {
         compute_oc_channel_blk();
     }
 
-    if (this->do_binary_) add(rsp, stack_space_needed);
+    if (this->do_binary_) add(rsp, stack_space_needed_);
     postamble();
 
     if (this->do_eltwise_) postops_injector_->prepare_table();
@@ -785,9 +875,10 @@ void jit_pp_kernel_t<acc_type, dst_type>::generate() {
 template <data_type_t acc_type, data_type_t dst_type>
 void jit_pp_kernel_t<acc_type, dst_type>::operator()(dst_data_t *dst,
         const acc_data_t *acc, const char *bias, const float *scales,
-        size_t start, size_t end, size_t runtime_oc, dim_t dst_mb_stride,
-        const float *dst_zero_points, const void *post_ops_binary_rhs_arg_vec,
-        const void *dst_orig, const exec_ctx_t & /* ctx */,
+        size_t start, size_t dst_logical_offset, size_t end, size_t runtime_oc,
+        dim_t dst_mb_stride, const float *dst_zero_points,
+        const void *post_ops_binary_rhs_arg_vec, const void *dst_orig,
+        const exec_ctx_t & /* ctx */,
         const memory_desc_t & /* dst_md */) const {
 
     if (end <= start) return;
@@ -815,6 +906,7 @@ void jit_pp_kernel_t<acc_type, dst_type>::operator()(dst_data_t *dst,
     args.oc = OC;
     args.len = end - start;
     args.oc_offset = oc_offset;
+    args.dst_logical_offset = dst_logical_offset;
     args.dst_mb_stride = dst_mb_stride;
 
     args.post_ops_binary_rhs_arg_vec = post_ops_binary_rhs_arg_vec;
diff --git a/tests/benchdnn/inputs/matmul/harness_matmul_runtime_f32 b/tests/benchdnn/inputs/matmul/harness_matmul_runtime_f32
index 80bd3bf99..02c30c9c8 100644
--- a/tests/benchdnn/inputs/matmul/harness_matmul_runtime_f32
+++ b/tests/benchdnn/inputs/matmul/harness_matmul_runtime_f32
@@ -13,5 +13,5 @@
 
 --runtime_m=1 --runtime_n=1 --runtime_k=1
 --attr-oscale=common:2.25*,per_oc:2.25*
---attr-post-ops='','sum;add:s8','mul:f32:per_oc'
+--attr-post-ops='','sum;add:s8','mul:f32:per_oc','mul:f32:per_tensor'
 --batch=shapes_2d
diff --git a/tests/benchdnn/inputs/matmul/harness_matmul_runtime_int8 b/tests/benchdnn/inputs/matmul/harness_matmul_runtime_int8
index 31183971e..d5412b279 100644
--- a/tests/benchdnn/inputs/matmul/harness_matmul_runtime_int8
+++ b/tests/benchdnn/inputs/matmul/harness_matmul_runtime_int8
@@ -31,7 +31,7 @@
 --batch=shapes_2d
 
 --attr-zero-points=src:common:1*_wei:common:-1*_dst:per_dim_1:2*
---attr-post-ops='add:f32:per_oc'
+--attr-post-ops='add:f32:per_oc','add:f32:per_tensor'
 --batch=shapes_2d
 
 # zero point doesn't belong to the data type (e.g. -1 is not u8)
@@ -39,4 +39,3 @@
 --runtime_m=0 --runtime_n=0 --runtime_k=0
 --bia_dt=undef
 --attr-oscale=common:1 --attr-zero-points=src:per_dim_1:-1*_wei:common:1_dst:common:2       --batch=shapes_2d
-
diff --git a/tests/benchdnn/inputs/matmul/test_matmul_all b/tests/benchdnn/inputs/matmul/test_matmul_all
index 4dc58e13e..5ecf5713f 100644
--- a/tests/benchdnn/inputs/matmul/test_matmul_all
+++ b/tests/benchdnn/inputs/matmul/test_matmul_all
@@ -36,7 +36,7 @@
 
 --runtime_mb=0,1 --runtime_m=1 --runtime_n=1 --runtime_k=0,1
 --attr-oscale=common:2.25
---attr-post-ops='sum;relu;add:u8'
+--attr-post-ops='sum;relu;add:u8','add:f32:per_tensor'
 --batch=shapes_3d
 
 # f32 Run-time
-- 
2.25.1

